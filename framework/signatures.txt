torch.ops.aten.abs(self)|Tensor
torch.ops.aten.abs.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.abs_(self)|Tensor(a!)
torch.ops.aten.absolute(self)|Tensor
torch.ops.aten.absolute.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.absolute_(self)|Tensor(a!)
torch.ops.aten.acos(self)|Tensor
torch.ops.aten.acos.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.acos.int(a)|int
torch.ops.aten.acos.float(a)|float
torch.ops.aten.acos.complex(a)|complex
torch.ops.aten.acos.Scalar(a)|Scalar
torch.ops.aten.acos_(self)|Tensor(a!)
torch.ops.aten.acosh(self)|Tensor
torch.ops.aten.acosh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.acosh.int(a)|int
torch.ops.aten.acosh.float(a)|float
torch.ops.aten.acosh.complex(a)|complex
torch.ops.aten.acosh.Scalar(a)|Scalar
torch.ops.aten.acosh_(self)|Tensor(a!)
torch.ops.aten.adaptive_max_pool2d(self,output_size)|Tensor,int[2]
torch.ops.aten.adaptive_max_pool2d.out(self,output_size,out,indices)|Tensor,int[2],Tensor(a!),Tensor(b!)
torch.ops.aten.adaptive_max_pool2d_backward(grad_output,self,indices)|Tensor,Tensor,Tensor
torch.ops.aten.adaptive_max_pool2d_backward.grad_input(grad_output,self,indices,grad_input)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.adaptive_max_pool3d(self,output_size)|Tensor,int[3]
torch.ops.aten.adaptive_max_pool3d.out(self,output_size,out,indices)|Tensor,int[3],Tensor(a!),Tensor(b!)
torch.ops.aten.adaptive_max_pool3d_backward(grad_output,self,indices)|Tensor,Tensor,Tensor
torch.ops.aten.adaptive_max_pool3d_backward.grad_input(grad_output,self,indices,grad_input)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.add.Tensor(self,other,alpha)|Tensor,Tensor,Scalar
torch.ops.aten.add.Scalar(self,other,alpha)|Tensor,Scalar,Scalar
torch.ops.aten.add.out(self,other,alpha,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.add.Scalar_out(self,other,alpha,out)|Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.add.t(a,b)|t[],t[]
torch.ops.aten.add.str(a,b)|str,str
torch.ops.aten.add.int(a,b)|int,int
torch.ops.aten.add.complex(a,b)|complex,complex
torch.ops.aten.add.float(a,b)|float,float
torch.ops.aten.add.int_complex(a,b)|int,complex
torch.ops.aten.add.complex_int(a,b)|complex,int
torch.ops.aten.add.float_complex(a,b)|float,complex
torch.ops.aten.add.complex_float(a,b)|complex,float
torch.ops.aten.add.int_float(a,b)|int,float
torch.ops.aten.add.float_int(a,b)|float,int
torch.ops.aten.add(a,b)|Scalar,Scalar
torch.ops.aten.add_.Tensor(self,other,alpha)|Tensor(a!),Tensor,Scalar
torch.ops.aten.add_.Scalar(self,other,alpha)|Tensor(a!),Scalar,Scalar
torch.ops.aten.add_.t(self,b)|t[](a!),t[]
torch.ops.aten.addbmm(self,batch1,batch2,beta,alpha)|Tensor,Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addbmm.out(self,batch1,batch2,beta,alpha,out)|Tensor,Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.addbmm_(self,batch1,batch2,beta,alpha)|Tensor(a!),Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addcdiv(self,tensor1,tensor2,value)|Tensor,Tensor,Tensor,Scalar
torch.ops.aten.addcdiv.out(self,tensor1,tensor2,value,out)|Tensor,Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.addcdiv_(self,tensor1,tensor2,value)|Tensor(a!),Tensor,Tensor,Scalar
torch.ops.aten.addcmul(self,tensor1,tensor2,value)|Tensor,Tensor,Tensor,Scalar
torch.ops.aten.addcmul.out(self,tensor1,tensor2,value,out)|Tensor,Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.addcmul_(self,tensor1,tensor2,value)|Tensor(a!),Tensor,Tensor,Scalar
torch.ops.aten.addmm(self,mat1,mat2,beta,alpha)|Tensor,Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addmm.out(self,mat1,mat2,beta,alpha,out)|Tensor,Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.addmm_(self,mat1,mat2,beta,alpha)|Tensor(a!),Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addmv(self,mat,vec,beta,alpha)|Tensor,Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addmv.out(self,mat,vec,beta,alpha,out)|Tensor,Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.addmv_(self,mat,vec,beta,alpha)|Tensor(a!),Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addr(self,vec1,vec2,beta,alpha)|Tensor,Tensor,Tensor,Scalar,Scalar
torch.ops.aten.addr.out(self,vec1,vec2,beta,alpha,out)|Tensor,Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.affine_grid_generator(theta,size,align_corners)|Tensor,SymInt[],bool
torch.ops.aten.affine_grid_generator.out(theta,size,align_corners,out)|Tensor,SymInt[],bool,Tensor(a!)
torch.ops.aten.alias(self)|Tensor(a)
torch.ops.aten.alias_copy(self)|Tensor
torch.ops.aten.alias_copy.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.all(self)|Tensor
torch.ops.aten.all.dim(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.all.dims(self,dim,keepdim)|Tensor,int[]?,bool
torch.ops.aten.all.out(self,dim,keepdim,out)|Tensor,int,bool,Tensor(a!)
torch.ops.aten.all.dims_out(self,dim,keepdim,out)|Tensor,int[]?,bool,Tensor(a!)
torch.ops.aten.all.all_out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.all.dimname(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.all.dimname_out(self,dim,keepdim,out)|Tensor,str,bool,Tensor(a!)
torch.ops.aten.all.int(self)|int[]
torch.ops.aten.all.float(self)|float[]
torch.ops.aten.all.bool(self)|bool[]
torch.ops.aten.alpha_dropout(input,p,train)|Tensor,float,bool
torch.ops.aten.amax(self,dim,keepdim)|Tensor,int[1],bool
torch.ops.aten.amax.out(self,dim,keepdim,out)|Tensor,int[1],bool,Tensor(a!)
torch.ops.aten.amin(self,dim,keepdim)|Tensor,int[1],bool
torch.ops.aten.amin.out(self,dim,keepdim,out)|Tensor,int[1],bool,Tensor(a!)
torch.ops.aten.aminmax(self,dim,keepdim)|Tensor,int?,bool
torch.ops.aten.aminmax.out(self,dim,keepdim,min,max)|Tensor,int?,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.angle(self)|Tensor
torch.ops.aten.angle.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.angle.int(a)|int
torch.ops.aten.angle.float(a)|float
torch.ops.aten.angle.complex(a)|complex
torch.ops.aten.angle.Scalar(a)|Scalar
torch.ops.aten.any(self)|Tensor
torch.ops.aten.any.dim(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.any.dims(self,dim,keepdim)|Tensor,int[]?,bool
torch.ops.aten.any.out(self,dim,keepdim,out)|Tensor,int,bool,Tensor(a!)
torch.ops.aten.any.dims_out(self,dim,keepdim,out)|Tensor,int[]?,bool,Tensor(a!)
torch.ops.aten.any.all_out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.any.dimname(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.any.dimname_out(self,dim,keepdim,out)|Tensor,str,bool,Tensor(a!)
torch.ops.aten.any.str(self)|str[]
torch.ops.aten.any.int(self)|int[]
torch.ops.aten.any.float(self)|float[]
torch.ops.aten.any.bool(self)|bool[]
torch.ops.aten.arange(end,dtype,layout,device,pin_memory)|Scalar,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.arange.start(start,end,dtype,layout,device,pin_memory)|Scalar,Scalar,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.arange.start_step(start,end,step,dtype,layout,device,pin_memory)|Scalar,Scalar,Scalar,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.arange.start_out(start,end,step,out)|Scalar,Scalar,Scalar,Tensor(a!)
torch.ops.aten.arange.out(end,out)|Scalar,Tensor(a!)
torch.ops.aten.arccos(self)|Tensor
torch.ops.aten.arccos.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.arccos_(self)|Tensor(a!)
torch.ops.aten.arccosh(self)|Tensor
torch.ops.aten.arccosh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.arccosh_(self)|Tensor(a!)
torch.ops.aten.arcsin(self)|Tensor
torch.ops.aten.arcsin.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.arcsin_(self)|Tensor(a!)
torch.ops.aten.arcsinh(self)|Tensor
torch.ops.aten.arcsinh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.arcsinh_(self)|Tensor(a!)
torch.ops.aten.arctan(self)|Tensor
torch.ops.aten.arctan.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.arctan2(self,other)|Tensor,Tensor
torch.ops.aten.arctan2.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.arctan2_(self,other)|Tensor(a!),Tensor
torch.ops.aten.arctan_(self)|Tensor(a!)
torch.ops.aten.arctanh(self)|Tensor
torch.ops.aten.arctanh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.arctanh_(self)|Tensor(a!)
torch.ops.aten.argmax(self,dim,keepdim)|Tensor,int?,bool
torch.ops.aten.argmax.out(self,dim,keepdim,out)|Tensor,int?,bool,Tensor(a!)
torch.ops.aten.argmin(self,dim,keepdim)|Tensor,int?,bool
torch.ops.aten.argmin.out(self,dim,keepdim,out)|Tensor,int?,bool,Tensor(a!)
torch.ops.aten.as_strided(self,size,stride,storage_offset)|Tensor(a),SymInt[],SymInt[],SymInt?
torch.ops.aten.as_strided_(self,size,stride,storage_offset)|Tensor(a!),SymInt[],SymInt[],SymInt?
torch.ops.aten.as_strided_copy(self,size,stride,storage_offset)|Tensor,SymInt[],SymInt[],SymInt?
torch.ops.aten.as_strided_copy.out(self,size,stride,storage_offset,out)|Tensor,SymInt[],SymInt[],SymInt?,Tensor(a!)
torch.ops.aten.as_strided_scatter(self,src,size,stride,storage_offset)|Tensor,Tensor,SymInt[],SymInt[],SymInt?
torch.ops.aten.as_strided_scatter.out(self,src,size,stride,storage_offset,out)|Tensor,Tensor,SymInt[],SymInt[],SymInt?,Tensor(a!)
torch.ops.aten.asin(self)|Tensor
torch.ops.aten.asin.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.asin.int(a)|int
torch.ops.aten.asin.float(a)|float
torch.ops.aten.asin.complex(a)|complex
torch.ops.aten.asin.Scalar(a)|Scalar
torch.ops.aten.asin_(self)|Tensor(a!)
torch.ops.aten.asinh(self)|Tensor
torch.ops.aten.asinh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.asinh.int(a)|int
torch.ops.aten.asinh.float(a)|float
torch.ops.aten.asinh.complex(a)|complex
torch.ops.aten.asinh.Scalar(a)|Scalar
torch.ops.aten.asinh_(self)|Tensor(a!)
torch.ops.aten.atan(self)|Tensor
torch.ops.aten.atan.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.atan.int(a)|int
torch.ops.aten.atan.float(a)|float
torch.ops.aten.atan.complex(a)|complex
torch.ops.aten.atan.Scalar(a)|Scalar
torch.ops.aten.atan2(self,other)|Tensor,Tensor
torch.ops.aten.atan2.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.atan2.int(a,b)|int,int
torch.ops.aten.atan2.float(a,b)|float,float
torch.ops.aten.atan2.int_float(a,b)|int,float
torch.ops.aten.atan2.float_int(a,b)|float,int
torch.ops.aten.atan2.Scalar_Scalar(a,b)|Scalar,Scalar
torch.ops.aten.atan2_(self,other)|Tensor(a!),Tensor
torch.ops.aten.atan_(self)|Tensor(a!)
torch.ops.aten.atanh(self)|Tensor
torch.ops.aten.atanh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.atanh.int(a)|int
torch.ops.aten.atanh.float(a)|float
torch.ops.aten.atanh.complex(a)|complex
torch.ops.aten.atanh.Scalar(a)|Scalar
torch.ops.aten.atanh_(self)|Tensor(a!)
torch.ops.aten.atleast_1d(self)|Tensor
torch.ops.aten.atleast_1d.Sequence(tensors)|Tensor[]
torch.ops.aten.atleast_2d(self)|Tensor
torch.ops.aten.atleast_2d.Sequence(tensors)|Tensor[]
torch.ops.aten.atleast_3d(self)|Tensor
torch.ops.aten.atleast_3d.Sequence(tensors)|Tensor[]
torch.ops.aten.avg_pool2d(self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override)|Tensor,int[2],int[2],int[2],bool,bool,int?
torch.ops.aten.avg_pool2d.out(self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override,out)|Tensor,int[2],int[2],int[2],bool,bool,int?,Tensor(a!)
torch.ops.aten.avg_pool2d_backward(grad_output,self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override)|Tensor,Tensor,int[2],int[2],int[2],bool,bool,int?
torch.ops.aten.avg_pool2d_backward.grad_input(grad_output,self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override,grad_input)|Tensor,Tensor,int[2],int[2],int[2],bool,bool,int?,Tensor(a!)
torch.ops.aten.avg_pool3d(self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override)|Tensor,int[3],int[3],int[3],bool,bool,int?
torch.ops.aten.avg_pool3d.out(self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override,out)|Tensor,int[3],int[3],int[3],bool,bool,int?,Tensor(a!)
torch.ops.aten.avg_pool3d_backward(grad_output,self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override)|Tensor,Tensor,int[3],int[3],int[3],bool,bool,int?
torch.ops.aten.avg_pool3d_backward.grad_input(grad_output,self,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override,grad_input)|Tensor,Tensor,int[3],int[3],int[3],bool,bool,int?,Tensor(a!)
torch.ops.aten.baddbmm(self,batch1,batch2,beta,alpha)|Tensor,Tensor,Tensor,Scalar,Scalar
torch.ops.aten.baddbmm.out(self,batch1,batch2,beta,alpha,out)|Tensor,Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.baddbmm_(self,batch1,batch2,beta,alpha)|Tensor(a!),Tensor,Tensor,Scalar,Scalar
torch.ops.aten.batch_norm(input,weight,bias,running_mean,running_var,training,momentum,eps,cudnn_enabled)|Tensor,Tensor?,Tensor?,Tensor?,Tensor?,bool,float,float,bool
torch.ops.aten.batch_norm_backward(grad_out,input,weight,running_mean,running_var,save_mean,save_var,update,eps,output_mask,reserve)|Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,bool,float,bool[3],Tensor
torch.ops.aten.bernoulli(self,generator)|Tensor,Generator?
torch.ops.aten.bernoulli.out(self,generator,out)|Tensor,Generator?,Tensor(a!)
torch.ops.aten.bernoulli.p(self,p,generator)|Tensor,float,Generator?
torch.ops.aten.bernoulli.Tensor(self,p,generator)|Tensor,Tensor,Generator?
torch.ops.aten.bernoulli.Tensor_out(self,p,generator,out)|Tensor,Tensor,Generator?,Tensor(a!)
torch.ops.aten.bernoulli.float_out(self,p,generator,out)|Tensor,float,Generator?,Tensor(a!)
torch.ops.aten.bernoulli_.Tensor(self,p,generator)|Tensor(a!),Tensor,Generator?
torch.ops.aten.bernoulli_.float(self,p,generator)|Tensor(a!),float,Generator?
torch.ops.aten.binary_cross_entropy(self,target,weight,reduction)|Tensor,Tensor,Tensor?,int
torch.ops.aten.binary_cross_entropy.out(self,target,weight,reduction,out)|Tensor,Tensor,Tensor?,int,Tensor(a!)
torch.ops.aten.binary_cross_entropy_backward(grad_output,self,target,weight,reduction)|Tensor,Tensor,Tensor,Tensor?,int
torch.ops.aten.binary_cross_entropy_backward.grad_input(grad_output,self,target,weight,reduction,grad_input)|Tensor,Tensor,Tensor,Tensor?,int,Tensor(a!)
torch.ops.aten.binary_cross_entropy_with_logits(self,target,weight,pos_weight,reduction)|Tensor,Tensor,Tensor?,Tensor?,int
torch.ops.aten.binary_cross_entropy_with_logits.out(self,target,weight,pos_weight,reduction,out)|Tensor,Tensor,Tensor?,Tensor?,int,Tensor(a!)
torch.ops.aten.bitwise_and.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.bitwise_and.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.bitwise_and.Scalar_Tensor(self,other)|Scalar,Tensor
torch.ops.aten.bitwise_and.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.bitwise_and.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.bitwise_and.Scalar_Tensor_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.bitwise_and_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.bitwise_and_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.bitwise_left_shift.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.bitwise_left_shift.Tensor_Scalar(self,other)|Tensor,Scalar
torch.ops.aten.bitwise_left_shift.Scalar_Tensor(self,other)|Scalar,Tensor
torch.ops.aten.bitwise_left_shift.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.bitwise_left_shift.Tensor_Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.bitwise_left_shift.Scalar_Tensor_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.bitwise_left_shift_.Tensor_Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.bitwise_left_shift_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.bitwise_not(self)|Tensor
torch.ops.aten.bitwise_not.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.bitwise_not_(self)|Tensor(a!)
torch.ops.aten.bitwise_or.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.bitwise_or.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.bitwise_or.Scalar_Tensor(self,other)|Scalar,Tensor
torch.ops.aten.bitwise_or.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.bitwise_or.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.bitwise_or.Scalar_Tensor_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.bitwise_or_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.bitwise_or_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.bitwise_right_shift.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.bitwise_right_shift.Tensor_Scalar(self,other)|Tensor,Scalar
torch.ops.aten.bitwise_right_shift.Scalar_Tensor(self,other)|Scalar,Tensor
torch.ops.aten.bitwise_right_shift.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.bitwise_right_shift.Tensor_Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.bitwise_right_shift.Scalar_Tensor_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.bitwise_right_shift_.Tensor_Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.bitwise_right_shift_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.bitwise_xor.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.bitwise_xor.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.bitwise_xor.Scalar_Tensor(self,other)|Scalar,Tensor
torch.ops.aten.bitwise_xor.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.bitwise_xor.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.bitwise_xor.Scalar_Tensor_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.bitwise_xor_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.bitwise_xor_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.block_diag(tensors)|Tensor[]
torch.ops.aten.block_diag.out(tensors,out)|Tensor[],Tensor(a!)
torch.ops.aten.bmm(self,mat2)|Tensor,Tensor
torch.ops.aten.bmm.out(self,mat2,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.broadcast_tensors(tensors)|Tensor[]
torch.ops.aten.bucketize.Tensor(self,boundaries,out_int32,right)|Tensor,Tensor,bool,bool
torch.ops.aten.bucketize.Scalar(self,boundaries,out_int32,right)|Scalar,Tensor,bool,bool
torch.ops.aten.bucketize.Tensor_out(self,boundaries,out_int32,right,out)|Tensor,Tensor,bool,bool,Tensor(a!)
torch.ops.aten.bucketize.Scalar_out(self,boundaries,out_int32,right,out)|Scalar,Tensor,bool,bool,Tensor(a!)
torch.ops.aten.cartesian_prod(tensors)|Tensor[]
torch.ops.aten.cat(tensors,dim)|Tensor[],int
torch.ops.aten.cat.names(tensors,dim)|Tensor[],str
torch.ops.aten.cat.names_out(tensors,dim,out)|Tensor[],str,Tensor(a!)
torch.ops.aten.cat.out(tensors,dim,out)|Tensor[],int,Tensor(a!)
torch.ops.aten.cauchy(self,median,sigma,generator)|Tensor,float,float,Generator?
torch.ops.aten.cauchy.out(self,median,sigma,generator,out)|Tensor,float,float,Generator?,Tensor(a!)
torch.ops.aten.cauchy_(self,median,sigma,generator)|Tensor(a!),float,float,Generator?
torch.ops.aten.ceil(self)|Tensor
torch.ops.aten.ceil.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.ceil.int(a)|int
torch.ops.aten.ceil.float(a)|float
torch.ops.aten.ceil.Scalar(a)|Scalar
torch.ops.aten.ceil_(self)|Tensor(a!)
torch.ops.aten.celu(self,alpha)|Tensor,Scalar
torch.ops.aten.celu.out(self,alpha,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.celu_(self,alpha)|Tensor(a!),Scalar
torch.ops.aten.channel_shuffle(self,groups)|Tensor,SymInt
torch.ops.aten.channel_shuffle.out(self,groups,out)|Tensor,SymInt,Tensor(a!)
torch.ops.aten.cholesky(self,upper)|Tensor,bool
torch.ops.aten.cholesky.out(self,upper,out)|Tensor,bool,Tensor(a!)
torch.ops.aten.cholesky_inverse(self,upper)|Tensor,bool
torch.ops.aten.cholesky_inverse.out(self,upper,out)|Tensor,bool,Tensor(a!)
torch.ops.aten.cholesky_solve(self,input2,upper)|Tensor,Tensor,bool
torch.ops.aten.cholesky_solve.out(self,input2,upper,out)|Tensor,Tensor,bool,Tensor(a!)
torch.ops.aten.clamp(self,min,max)|Tensor,Scalar?,Scalar?
torch.ops.aten.clamp.Tensor(self,min,max)|Tensor,Tensor?,Tensor?
torch.ops.aten.clamp.out(self,min,max,out)|Tensor,Scalar?,Scalar?,Tensor(a!)
torch.ops.aten.clamp.Tensor_out(self,min,max,out)|Tensor,Tensor?,Tensor?,Tensor(a!)
torch.ops.aten.clamp_(self,min,max)|Tensor(a!),Scalar?,Scalar?
torch.ops.aten.clamp_.Tensor(self,min,max)|Tensor(a!),Tensor?,Tensor?
torch.ops.aten.clamp_max(self,max)|Tensor,Scalar
torch.ops.aten.clamp_max.Tensor(self,max)|Tensor,Tensor
torch.ops.aten.clamp_max.out(self,max,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.clamp_max.Tensor_out(self,max,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.clamp_max_(self,max)|Tensor(a!),Scalar
torch.ops.aten.clamp_max_.Tensor(self,max)|Tensor(a!),Tensor
torch.ops.aten.clamp_min(self,min)|Tensor,Scalar
torch.ops.aten.clamp_min.Tensor(self,min)|Tensor,Tensor
torch.ops.aten.clamp_min.out(self,min,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.clamp_min.Tensor_out(self,min,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.clamp_min_(self,min)|Tensor(a!),Scalar
torch.ops.aten.clamp_min_.Tensor(self,min)|Tensor(a!),Tensor
torch.ops.aten.clip(self,min,max)|Tensor,Scalar?,Scalar?
torch.ops.aten.clip.Tensor(self,min,max)|Tensor,Tensor?,Tensor?
torch.ops.aten.clip.out(self,min,max,out)|Tensor,Scalar?,Scalar?,Tensor(a!)
torch.ops.aten.clip.Tensor_out(self,min,max,out)|Tensor,Tensor?,Tensor?,Tensor(a!)
torch.ops.aten.clip_(self,min,max)|Tensor(a!),Scalar?,Scalar?
torch.ops.aten.clip_.Tensor(self,min,max)|Tensor(a!),Tensor?,Tensor?
torch.ops.aten.clone(self,memory_format)|Tensor,MemoryFormat?
torch.ops.aten.clone.out(self,memory_format,out)|Tensor,MemoryFormat?,Tensor(a!)
torch.ops.aten.col2im(self,output_size,kernel_size,dilation,padding,stride)|Tensor,SymInt[2],int[2],int[2],int[2],int[2]
torch.ops.aten.col2im.out(self,output_size,kernel_size,dilation,padding,stride,out)|Tensor,SymInt[2],int[2],int[2],int[2],int[2],Tensor(a!)
torch.ops.aten.complex(real,imag)|Tensor,Tensor
torch.ops.aten.complex.out(real,imag,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.conj(self)|Tensor(a)
torch.ops.aten.conj_physical(self)|Tensor
torch.ops.aten.conj_physical.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.conj_physical_(self)|Tensor(a!)
torch.ops.aten.constant_pad_nd(self,pad,value)|Tensor,SymInt[],Scalar
torch.ops.aten.constant_pad_nd.out(self,pad,value,out)|Tensor,SymInt[],Scalar,Tensor(a!)
torch.ops.aten.conv2d(input,weight,bias,stride,padding,dilation,groups)|Tensor,Tensor,Tensor?,SymInt[2],SymInt[2],SymInt[2],SymInt
torch.ops.aten.conv2d.padding(input,weight,bias,stride,padding,dilation,groups)|Tensor,Tensor,Tensor?,SymInt[2],str,SymInt[2],SymInt
torch.ops.aten.convolution(input,weight,bias,stride,padding,dilation,transposed,output_padding,groups)|Tensor,Tensor,Tensor?,SymInt[],SymInt[],SymInt[],bool,SymInt[],SymInt
torch.ops.aten.convolution.out(input,weight,bias,stride,padding,dilation,transposed,output_padding,groups,out)|Tensor,Tensor,Tensor?,SymInt[],SymInt[],SymInt[],bool,SymInt[],SymInt,Tensor(a!)
torch.ops.aten.convolution_backward(grad_output,input,weight,bias_sizes,stride,padding,dilation,transposed,output_padding,groups,output_mask)|Tensor,Tensor,Tensor,SymInt[]?,SymInt[],SymInt[],SymInt[],bool,SymInt[],SymInt,bool[3]
torch.ops.aten.convolution_backward.out(grad_output,input,weight,bias_sizes,stride,padding,dilation,transposed,output_padding,groups,output_mask,out0,out1,out2)|Tensor,Tensor,Tensor,SymInt[]?,SymInt[],SymInt[],SymInt[],bool,SymInt[],SymInt,bool[3],Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.copy.out(self,src,non_blocking,out)|Tensor,Tensor,bool,Tensor(a!)
torch.ops.aten.copy(self,src,non_blocking)|Tensor,Tensor,bool
torch.ops.aten.copy.t(self)|t[](a)
torch.ops.aten.copy.Dict_str(t)|Dict(str,
torch.ops.aten.copy.Dict_int(t)|Dict(int,
torch.ops.aten.copy.Dict_bool(t)|Dict(bool,
torch.ops.aten.copy.Dict_float(t)|Dict(float,
torch.ops.aten.copy.Dict_complex(t)|Dict(complex,
torch.ops.aten.copy.Dict_Tensor(t)|Dict(Tensor,
torch.ops.aten.copy_(self,src,non_blocking)|Tensor(a!),Tensor,bool
torch.ops.aten.copy_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.copy_.int(self,other)|Tensor(a!),int
torch.ops.aten.copy_.float(self,other)|Tensor(a!),float
torch.ops.aten.copysign.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.copysign.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.copysign.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.copysign.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.copysign.int(a,b)|int,int
torch.ops.aten.copysign.float(a,b)|float,float
torch.ops.aten.copysign.int_float(a,b)|int,float
torch.ops.aten.copysign.float_int(a,b)|float,int
torch.ops.aten.copysign(a,b)|Scalar,Scalar
torch.ops.aten.copysign_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.copysign_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.cos(self)|Tensor
torch.ops.aten.cos.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.cos.int(a)|int
torch.ops.aten.cos.float(a)|float
torch.ops.aten.cos.complex(a)|complex
torch.ops.aten.cos.Scalar(a)|Scalar
torch.ops.aten.cos_(self)|Tensor(a!)
torch.ops.aten.cosh(self)|Tensor
torch.ops.aten.cosh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.cosh.int(a)|int
torch.ops.aten.cosh.float(a)|float
torch.ops.aten.cosh.complex(a)|complex
torch.ops.aten.cosh.Scalar(a)|Scalar
torch.ops.aten.cosh_(self)|Tensor(a!)
torch.ops.aten.count_nonzero.dim_IntList(self,dim)|Tensor,int[]
torch.ops.aten.count_nonzero.dim_IntList_out(self,dim,out)|Tensor,int[],Tensor(a!)
torch.ops.aten.count_nonzero(self,dim)|Tensor,int?
torch.ops.aten.count_nonzero.out(self,dim,out)|Tensor,int?,Tensor(a!)
torch.ops.aten.cudnn_batch_norm(input,weight,bias,running_mean,running_var,training,exponential_average_factor,epsilon)|Tensor,Tensor,Tensor?,Tensor?,Tensor?,bool,float,float
torch.ops.aten.cudnn_batch_norm.out(input,weight,bias,running_mean,running_var,training,exponential_average_factor,epsilon,out0,out1,out2,out3)|Tensor,Tensor,Tensor?,Tensor?,Tensor?,bool,float,float,Tensor(a!),Tensor(b!),Tensor(c!),Tensor(d!)
torch.ops.aten.cudnn_batch_norm_backward(input,grad_output,weight,running_mean,running_var,save_mean,save_var,epsilon,reserveSpace)|Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,float,Tensor
torch.ops.aten.cudnn_batch_norm_backward.out(input,grad_output,weight,running_mean,running_var,save_mean,save_var,epsilon,reserveSpace,out0,out1,out2)|Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,float,Tensor,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.cummax(self,dim)|Tensor,int
torch.ops.aten.cummax.dimname(self,dim)|Tensor,str
torch.ops.aten.cummax.dimname_out(self,dim,values,indices)|Tensor,str,Tensor(a!),Tensor(b!)
torch.ops.aten.cummax.out(self,dim,values,indices)|Tensor,int,Tensor(a!),Tensor(b!)
torch.ops.aten.cummin(self,dim)|Tensor,int
torch.ops.aten.cummin.dimname(self,dim)|Tensor,str
torch.ops.aten.cummin.dimname_out(self,dim,values,indices)|Tensor,str,Tensor(a!),Tensor(b!)
torch.ops.aten.cummin.out(self,dim,values,indices)|Tensor,int,Tensor(a!),Tensor(b!)
torch.ops.aten.cumprod(self,dim,dtype)|Tensor,int,ScalarType?
torch.ops.aten.cumprod.dimname(self,dim,dtype)|Tensor,str,ScalarType?
torch.ops.aten.cumprod.dimname_out(self,dim,dtype,out)|Tensor,str,ScalarType?,Tensor(a!)
torch.ops.aten.cumprod.out(self,dim,dtype,out)|Tensor,int,ScalarType?,Tensor(a!)
torch.ops.aten.cumprod_(self,dim,dtype)|Tensor(a!),int,ScalarType?
torch.ops.aten.cumprod_.dimname(self,dim,dtype)|Tensor(a!),str,ScalarType?
torch.ops.aten.cumsum(self,dim,dtype)|Tensor,int,ScalarType?
torch.ops.aten.cumsum.dimname(self,dim,dtype)|Tensor,str,ScalarType?
torch.ops.aten.cumsum.dimname_out(self,dim,dtype,out)|Tensor,str,ScalarType?,Tensor(a!)
torch.ops.aten.cumsum.out(self,dim,dtype,out)|Tensor,int,ScalarType?,Tensor(a!)
torch.ops.aten.cumsum_(self,dim,dtype)|Tensor(a!),int,ScalarType?
torch.ops.aten.cumsum_.dimname(self,dim,dtype)|Tensor(a!),str,ScalarType?
torch.ops.aten.deg2rad(self)|Tensor
torch.ops.aten.deg2rad.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.deg2rad_(self)|Tensor(a!)
torch.ops.aten.dense_dim(self)|Tensor
torch.ops.aten.detach(self)|Tensor(a)
torch.ops.aten.diag(self,diagonal)|Tensor,int
torch.ops.aten.diag.out(self,diagonal,out)|Tensor,int,Tensor(a!)
torch.ops.aten.diag_embed(self,offset,dim1,dim2)|Tensor,int,int,int
torch.ops.aten.diag_embed.out(self,offset,dim1,dim2,out)|Tensor,int,int,int,Tensor(a!)
torch.ops.aten.diagonal(self,offset,dim1,dim2)|Tensor(a),int,int,int
torch.ops.aten.diagonal.Dimname(self,outdim,dim1,dim2,offset)|Tensor(a),str,str,str,int
torch.ops.aten.diagonal_backward(grad_output,input_sizes,offset,dim1,dim2)|Tensor,SymInt[],int,int,int
torch.ops.aten.diagonal_backward.out(grad_output,input_sizes,offset,dim1,dim2,out)|Tensor,SymInt[],int,int,int,Tensor(a!)
torch.ops.aten.diagonal_copy(self,offset,dim1,dim2)|Tensor,int,int,int
torch.ops.aten.diagonal_copy.out(self,offset,dim1,dim2,out)|Tensor,int,int,int,Tensor(a!)
torch.ops.aten.diagonal_scatter(self,src,offset,dim1,dim2)|Tensor,Tensor,int,int,int
torch.ops.aten.diagonal_scatter.out(self,src,offset,dim1,dim2,out)|Tensor,Tensor,int,int,int,Tensor(a!)
torch.ops.aten.digamma(self)|Tensor
torch.ops.aten.digamma.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.digamma_(self)|Tensor(a!)
torch.ops.aten.dim(self)|Tensor
torch.ops.aten.dist(self,other,p)|Tensor,Tensor,Scalar
torch.ops.aten.dist.out(self,other,p,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.div.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.div.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.div.Tensor_mode(self,other,rounding_mode)|Tensor,Tensor,str?
torch.ops.aten.div.Scalar_mode(self,other,rounding_mode)|Tensor,Scalar,str?
torch.ops.aten.div.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.div.out_mode(self,other,rounding_mode,out)|Tensor,Tensor,str?,Tensor(a!)
torch.ops.aten.div.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.div.Scalar_mode_out(self,other,rounding_mode,out)|Tensor,Scalar,str?,Tensor(a!)
torch.ops.aten.div.int(a,b)|int,int
torch.ops.aten.div.complex(a,b)|complex,complex
torch.ops.aten.div.float(a,b)|float,float
torch.ops.aten.div(a,b)|Scalar,Scalar
torch.ops.aten.div_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.div_.Tensor_mode(self,other,rounding_mode)|Tensor(a!),Tensor,str?
torch.ops.aten.div_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.div_.Scalar_mode(self,other,rounding_mode)|Tensor(a!),Scalar,str?
torch.ops.aten.divide.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.divide.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.divide.Tensor_mode(self,other,rounding_mode)|Tensor,Tensor,str?
torch.ops.aten.divide.Scalar_mode(self,other,rounding_mode)|Tensor,Scalar,str?
torch.ops.aten.divide.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.divide.out_mode(self,other,rounding_mode,out)|Tensor,Tensor,str?,Tensor(a!)
torch.ops.aten.divide_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.divide_.Tensor_mode(self,other,rounding_mode)|Tensor(a!),Tensor,str?
torch.ops.aten.divide_.Scalar_mode(self,other,rounding_mode)|Tensor(a!),Scalar,str?
torch.ops.aten.divide_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.dot(self,tensor)|Tensor,Tensor
torch.ops.aten.dot.out(self,tensor,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.dropout(input,p,train)|Tensor,float,bool
torch.ops.aten.elu(self,alpha,scale,input_scale)|Tensor,Scalar,Scalar,Scalar
torch.ops.aten.elu.out(self,alpha,scale,input_scale,out)|Tensor,Scalar,Scalar,Scalar,Tensor(a!)
torch.ops.aten.elu_(self,alpha,scale,input_scale)|Tensor(a!),Scalar,Scalar,Scalar
torch.ops.aten.elu_backward(grad_output,alpha,scale,input_scale,is_result,self_or_result)|Tensor,Scalar,Scalar,Scalar,bool,Tensor
torch.ops.aten.elu_backward.grad_input(grad_output,alpha,scale,input_scale,is_result,self_or_result,grad_input)|Tensor,Scalar,Scalar,Scalar,bool,Tensor,Tensor(a!)
torch.ops.aten.embedding(weight,indices,padding_idx,scale_grad_by_freq,sparse)|Tensor,Tensor,SymInt,bool,bool
torch.ops.aten.embedding.out(weight,indices,padding_idx,scale_grad_by_freq,sparse,out)|Tensor,Tensor,SymInt,bool,bool,Tensor(a!)
torch.ops.aten.embedding_dense_backward(grad_output,indices,num_weights,padding_idx,scale_grad_by_freq)|Tensor,Tensor,SymInt,SymInt,bool
torch.ops.aten.embedding_dense_backward.out(grad_output,indices,num_weights,padding_idx,scale_grad_by_freq,out)|Tensor,Tensor,SymInt,SymInt,bool,Tensor(a!)
torch.ops.aten.empty.memory_format(size,dtype,layout,device,pin_memory,memory_format)|SymInt[],ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.empty.out(size,memory_format,out)|SymInt[],MemoryFormat?,Tensor(a!)
torch.ops.aten.empty.names(size,names,dtype,layout,device,pin_memory,memory_format)|int[],str[]?,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.empty.names_out(size,names,memory_format,out)|int[],str[]?,MemoryFormat?,Tensor(a!)
torch.ops.aten.empty_like(self,dtype,layout,device,pin_memory,memory_format)|Tensor,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.empty_like.out(self,memory_format,out)|Tensor,MemoryFormat?,Tensor(a!)
torch.ops.aten.empty_permuted(size,physical_layout,dtype,layout,device,pin_memory)|SymInt[],int[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.empty_permuted.out(size,physical_layout,out)|SymInt[],int[],Tensor(a!)
torch.ops.aten.empty_strided(size,stride,dtype,layout,device,pin_memory)|SymInt[],SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.empty_strided.out(size,stride,out)|SymInt[],SymInt[],Tensor(a!)
torch.ops.aten.eq.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.eq.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.eq.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.eq.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.eq.int_list(a,b)|int[],int[]
torch.ops.aten.eq.device(a,b)|Device,Device
torch.ops.aten.eq.bool(a,b)|bool,bool
torch.ops.aten.eq.enum(a,b)|AnyEnumType,AnyEnumType
torch.ops.aten.eq.int(a,b)|int,int
torch.ops.aten.eq.complex(a,b)|complex,complex
torch.ops.aten.eq.float(a,b)|float,float
torch.ops.aten.eq.int_float(a,b)|int,float
torch.ops.aten.eq.float_int(a,b)|float,int
torch.ops.aten.eq.float_complex(a,b)|float,complex
torch.ops.aten.eq.complex_float(a,b)|complex,float
torch.ops.aten.eq(a,b)|Scalar,Scalar
torch.ops.aten.eq.str(a,b)|str,str
torch.ops.aten.eq.float_list(a,b)|float[],float[]
torch.ops.aten.eq.Tensor_list(a,b)|Tensor[],Tensor[]
torch.ops.aten.eq.bool_list(a,b)|bool[],bool[]
torch.ops.aten.eq.str_list(a,b)|str[],str[]
torch.ops.aten.eq_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.eq_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.erf(self)|Tensor
torch.ops.aten.erf.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.erf.int(a)|int
torch.ops.aten.erf.float(a)|float
torch.ops.aten.erf.Scalar(a)|Scalar
torch.ops.aten.erf_(self)|Tensor(a!)
torch.ops.aten.erfc(self)|Tensor
torch.ops.aten.erfc.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.erfc.int(a)|int
torch.ops.aten.erfc.float(a)|float
torch.ops.aten.erfc.Scalar(a)|Scalar
torch.ops.aten.erfc_(self)|Tensor(a!)
torch.ops.aten.erfinv(self)|Tensor
torch.ops.aten.erfinv.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.erfinv_(self)|Tensor(a!)
torch.ops.aten.exp(self)|Tensor
torch.ops.aten.exp.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.exp.int(a)|int
torch.ops.aten.exp.float(a)|float
torch.ops.aten.exp.complex(a)|complex
torch.ops.aten.exp.Scalar(a)|Scalar
torch.ops.aten.exp2(self)|Tensor
torch.ops.aten.exp2.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.exp2_(self)|Tensor(a!)
torch.ops.aten.exp_(self)|Tensor(a!)
torch.ops.aten.expand(self,size,implicit)|Tensor(a),SymInt[],bool
torch.ops.aten.expand_copy(self,size,implicit)|Tensor,SymInt[],bool
torch.ops.aten.expand_copy.out(self,size,implicit,out)|Tensor,SymInt[],bool,Tensor(a!)
torch.ops.aten.expm1(self)|Tensor
torch.ops.aten.expm1.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.expm1.int(a)|int
torch.ops.aten.expm1.float(a)|float
torch.ops.aten.expm1.Scalar(a)|Scalar
torch.ops.aten.expm1_(self)|Tensor(a!)
torch.ops.aten.exponential(self,lambd,generator)|Tensor,float,Generator?
torch.ops.aten.exponential.out(self,lambd,generator,out)|Tensor,float,Generator?,Tensor(a!)
torch.ops.aten.exponential_(self,lambd,generator)|Tensor(a!),float,Generator?
torch.ops.aten.eye(n,dtype,layout,device,pin_memory)|SymInt,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.eye.m(n,m,dtype,layout,device,pin_memory)|SymInt,SymInt,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.eye.out(n,out)|SymInt,Tensor(a!)
torch.ops.aten.eye.m_out(n,m,out)|SymInt,SymInt,Tensor(a!)
torch.ops.aten.feature_alpha_dropout(input,p,train)|Tensor,float,bool
torch.ops.aten.feature_dropout(input,p,train)|Tensor,float,bool
torch.ops.aten.fft_fft(self,n,dim,norm)|Tensor,SymInt?,int,str?
torch.ops.aten.fft_fft.out(self,n,dim,norm,out)|Tensor,SymInt?,int,str?,Tensor(a!)
torch.ops.aten.fft_fft2(self,s,dim,norm)|Tensor,SymInt[1]?,int[1],str?
torch.ops.aten.fft_fft2.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1],str?,Tensor(a!)
torch.ops.aten.fft_fftn(self,s,dim,norm)|Tensor,SymInt[1]?,int[1]?,str?
torch.ops.aten.fft_fftn.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1]?,str?,Tensor(a!)
torch.ops.aten.fft_fftshift(self,dim)|Tensor,int[1]?
torch.ops.aten.fft_hfft(self,n,dim,norm)|Tensor,SymInt?,int,str?
torch.ops.aten.fft_hfft.out(self,n,dim,norm,out)|Tensor,SymInt?,int,str?,Tensor(a!)
torch.ops.aten.fft_hfft2(self,s,dim,norm)|Tensor,SymInt[1]?,int[1],str?
torch.ops.aten.fft_hfft2.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1],str?,Tensor(a!)
torch.ops.aten.fft_hfftn(self,s,dim,norm)|Tensor,SymInt[1]?,int[1]?,str?
torch.ops.aten.fft_hfftn.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1]?,str?,Tensor(a!)
torch.ops.aten.fft_ifft(self,n,dim,norm)|Tensor,SymInt?,int,str?
torch.ops.aten.fft_ifft.out(self,n,dim,norm,out)|Tensor,SymInt?,int,str?,Tensor(a!)
torch.ops.aten.fft_ifft2(self,s,dim,norm)|Tensor,SymInt[1]?,int[1],str?
torch.ops.aten.fft_ifft2.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1],str?,Tensor(a!)
torch.ops.aten.fft_ifftn(self,s,dim,norm)|Tensor,SymInt[1]?,int[1]?,str?
torch.ops.aten.fft_ifftn.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1]?,str?,Tensor(a!)
torch.ops.aten.fft_ifftshift(self,dim)|Tensor,int[1]?
torch.ops.aten.fft_ihfft(self,n,dim,norm)|Tensor,SymInt?,int,str?
torch.ops.aten.fft_ihfft.out(self,n,dim,norm,out)|Tensor,SymInt?,int,str?,Tensor(a!)
torch.ops.aten.fft_ihfft2(self,s,dim,norm)|Tensor,SymInt[1]?,int[1],str?
torch.ops.aten.fft_ihfft2.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1],str?,Tensor(a!)
torch.ops.aten.fft_ihfftn(self,s,dim,norm)|Tensor,SymInt[1]?,int[1]?,str?
torch.ops.aten.fft_ihfftn.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1]?,str?,Tensor(a!)
torch.ops.aten.fft_irfft(self,n,dim,norm)|Tensor,SymInt?,int,str?
torch.ops.aten.fft_irfft.out(self,n,dim,norm,out)|Tensor,SymInt?,int,str?,Tensor(a!)
torch.ops.aten.fft_irfft2(self,s,dim,norm)|Tensor,SymInt[1]?,int[1],str?
torch.ops.aten.fft_irfft2.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1],str?,Tensor(a!)
torch.ops.aten.fft_irfftn(self,s,dim,norm)|Tensor,SymInt[1]?,int[1]?,str?
torch.ops.aten.fft_irfftn.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1]?,str?,Tensor(a!)
torch.ops.aten.fft_rfft(self,n,dim,norm)|Tensor,SymInt?,int,str?
torch.ops.aten.fft_rfft.out(self,n,dim,norm,out)|Tensor,SymInt?,int,str?,Tensor(a!)
torch.ops.aten.fft_rfft2(self,s,dim,norm)|Tensor,SymInt[1]?,int[1],str?
torch.ops.aten.fft_rfft2.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1],str?,Tensor(a!)
torch.ops.aten.fft_rfftn(self,s,dim,norm)|Tensor,SymInt[1]?,int[1]?,str?
torch.ops.aten.fft_rfftn.out(self,s,dim,norm,out)|Tensor,SymInt[1]?,int[1]?,str?,Tensor(a!)
torch.ops.aten.fill.Scalar(self,value)|Tensor,Scalar
torch.ops.aten.fill.Scalar_out(self,value,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.fill.Tensor(self,value)|Tensor,Tensor
torch.ops.aten.fill.Tensor_out(self,value,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.fill_.Scalar(self,value)|Tensor(a!),Scalar
torch.ops.aten.fill_.Tensor(self,value)|Tensor(a!),Tensor
torch.ops.aten.fix(self)|Tensor
torch.ops.aten.fix.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.fix_(self)|Tensor(a!)
torch.ops.aten.flip(self,dims)|Tensor,int[]
torch.ops.aten.flip.out(self,dims,out)|Tensor,int[],Tensor(a!)
torch.ops.aten.float_power_.Tensor(self,exponent)|Tensor(a!),Tensor
torch.ops.aten.float_power_.Scalar(self,exponent)|Tensor(a!),Scalar
torch.ops.aten.floor(self)|Tensor
torch.ops.aten.floor.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.floor.int(a)|int
torch.ops.aten.floor.float(a)|float
torch.ops.aten.floor.Scalar(a)|Scalar
torch.ops.aten.floor_(self)|Tensor(a!)
torch.ops.aten.floor_divide(self,other)|Tensor,Tensor
torch.ops.aten.floor_divide.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.floor_divide.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.floor_divide.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.floor_divide_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.floor_divide_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.fmax(self,other)|Tensor,Tensor
torch.ops.aten.fmax.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.fmin(self,other)|Tensor,Tensor
torch.ops.aten.fmin.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.fmod.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.fmod.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.fmod.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.fmod.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.fmod.int(a,b)|int,int
torch.ops.aten.fmod.float(a,b)|float,float
torch.ops.aten.fmod.int_float(a,b)|int,float
torch.ops.aten.fmod.float_int(a,b)|float,int
torch.ops.aten.fmod(a,b)|Scalar,Scalar
torch.ops.aten.fmod_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.fmod_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.frac(self)|Tensor
torch.ops.aten.frac.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.frac_(self)|Tensor(a!)
torch.ops.aten.fractional_max_pool2d(self,kernel_size,output_size,random_samples)|Tensor,int[2],int[2],Tensor
torch.ops.aten.fractional_max_pool2d.output(self,kernel_size,output_size,random_samples,output,indices)|Tensor,int[2],int[2],Tensor,Tensor(a!),Tensor(b!)
torch.ops.aten.frexp.Tensor(self)|Tensor
torch.ops.aten.frexp.Tensor_out(self,mantissa,exponent)|Tensor,Tensor(a!),Tensor(b!)
torch.ops.aten.frexp(a)|float
torch.ops.aten.full.names(size,fill_value,names,dtype,layout,device,pin_memory)|int[],Scalar,str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.full(size,fill_value,dtype,layout,device,pin_memory)|SymInt[],Scalar,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.full.names_out(size,fill_value,names,out)|int[],Scalar,str[]?,Tensor(a!)
torch.ops.aten.full.out(size,fill_value,out)|SymInt[],Scalar,Tensor(a!)
torch.ops.aten.full_like(self,fill_value,dtype,layout,device,pin_memory,memory_format)|Tensor,Scalar,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.full_like.out(self,fill_value,memory_format,out)|Tensor,Scalar,MemoryFormat?,Tensor(a!)
torch.ops.aten.gather(self,dim,index,sparse_grad)|Tensor,int,Tensor,bool
torch.ops.aten.gather.out(self,dim,index,sparse_grad,out)|Tensor,int,Tensor,bool,Tensor(a!)
torch.ops.aten.gather.dimname(self,dim,index,sparse_grad)|Tensor,str,Tensor,bool
torch.ops.aten.gather.dimname_out(self,dim,index,sparse_grad,out)|Tensor,str,Tensor,bool,Tensor(a!)
torch.ops.aten.gcd(self,other)|Tensor,Tensor
torch.ops.aten.gcd.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.gcd.int(a,b)|int,int
torch.ops.aten.gcd_(self,other)|Tensor(a!),Tensor
torch.ops.aten.ge.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.ge.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.ge.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.ge.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.ge.int(a,b)|int,int
torch.ops.aten.ge.float(a,b)|float,float
torch.ops.aten.ge.int_float(a,b)|int,float
torch.ops.aten.ge.float_int(a,b)|float,int
torch.ops.aten.ge(a,b)|Scalar,Scalar
torch.ops.aten.ge.str(a,b)|str,str
torch.ops.aten.ge_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.ge_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.gelu(self,approximate)|Tensor,str
torch.ops.aten.gelu.out(self,approximate,out)|Tensor,str,Tensor(a!)
torch.ops.aten.gelu_(self,approximate)|Tensor(a!),str
torch.ops.aten.gelu_backward(grad_output,self,approximate)|Tensor,Tensor,str
torch.ops.aten.gelu_backward.grad_input(grad_output,self,approximate,grad_input)|Tensor,Tensor,str,Tensor(a!)
torch.ops.aten.geometric(self,p,generator)|Tensor,float,Generator?
torch.ops.aten.geometric.out(self,p,generator,out)|Tensor,float,Generator?,Tensor(a!)
torch.ops.aten.geometric_(self,p,generator)|Tensor(a!),float,Generator?
torch.ops.aten.glu(self,dim)|Tensor,int
torch.ops.aten.glu.out(self,dim,out)|Tensor,int,Tensor(a!)
torch.ops.aten.glu_backward(grad_output,self,dim)|Tensor,Tensor,int
torch.ops.aten.glu_backward.grad_input(grad_output,self,dim,grad_input)|Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.greater.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.greater.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.greater.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.greater.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.greater_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.greater_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.greater_equal.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.greater_equal.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.greater_equal.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.greater_equal.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.greater_equal_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.greater_equal_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.grid_sampler_2d(input,grid,interpolation_mode,padding_mode,align_corners)|Tensor,Tensor,int,int,bool
torch.ops.aten.grid_sampler_2d.out(input,grid,interpolation_mode,padding_mode,align_corners,out)|Tensor,Tensor,int,int,bool,Tensor(a!)
torch.ops.aten.grid_sampler_2d_backward(grad_output,input,grid,interpolation_mode,padding_mode,align_corners,output_mask)|Tensor,Tensor,Tensor,int,int,bool,bool[2]
torch.ops.aten.grid_sampler_2d_backward.out(grad_output,input,grid,interpolation_mode,padding_mode,align_corners,output_mask,out0,out1)|Tensor,Tensor,Tensor,int,int,bool,bool[2],Tensor(a!),Tensor(b!)
torch.ops.aten.grid_sampler_3d(input,grid,interpolation_mode,padding_mode,align_corners)|Tensor,Tensor,int,int,bool
torch.ops.aten.grid_sampler_3d.out(input,grid,interpolation_mode,padding_mode,align_corners,out)|Tensor,Tensor,int,int,bool,Tensor(a!)
torch.ops.aten.grid_sampler_3d_backward(grad_output,input,grid,interpolation_mode,padding_mode,align_corners,output_mask)|Tensor,Tensor,Tensor,int,int,bool,bool[2]
torch.ops.aten.grid_sampler_3d_backward.out(grad_output,input,grid,interpolation_mode,padding_mode,align_corners,output_mask,out0,out1)|Tensor,Tensor,Tensor,int,int,bool,bool[2],Tensor(a!),Tensor(b!)
torch.ops.aten.gru.input(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first)|Tensor,Tensor,Tensor[],bool,int,float,bool,bool,bool
torch.ops.aten.gru.data(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional)|Tensor,Tensor,Tensor,Tensor[],bool,int,float,bool,bool
torch.ops.aten.gt.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.gt.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.gt.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.gt.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.gt.int(a,b)|int,int
torch.ops.aten.gt.float(a,b)|float,float
torch.ops.aten.gt.int_float(a,b)|int,float
torch.ops.aten.gt.float_int(a,b)|float,int
torch.ops.aten.gt(a,b)|Scalar,Scalar
torch.ops.aten.gt.str(a,b)|str,str
torch.ops.aten.gt_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.gt_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.hardshrink(self,lambd)|Tensor,Scalar
torch.ops.aten.hardshrink.out(self,lambd,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.hardsigmoid(self)|Tensor
torch.ops.aten.hardsigmoid.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.hardsigmoid_(self)|Tensor(a!)
torch.ops.aten.hardsigmoid_backward(grad_output,self)|Tensor,Tensor
torch.ops.aten.hardsigmoid_backward.grad_input(grad_output,self,grad_input)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.hardswish(self)|Tensor
torch.ops.aten.hardswish.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.hardswish_(self)|Tensor(a!)
torch.ops.aten.hardswish_backward(grad_output,self)|Tensor,Tensor
torch.ops.aten.hardswish_backward.out(grad_output,self,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.hardtanh(self,min_val,max_val)|Tensor,Scalar,Scalar
torch.ops.aten.hardtanh.out(self,min_val,max_val,out)|Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.hardtanh_(self,min_val,max_val)|Tensor(a!),Scalar,Scalar
torch.ops.aten.hardtanh_backward(grad_output,self,min_val,max_val)|Tensor,Tensor,Scalar,Scalar
torch.ops.aten.hardtanh_backward.grad_input(grad_output,self,min_val,max_val,grad_input)|Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.heaviside(self,values)|Tensor,Tensor
torch.ops.aten.heaviside.out(self,values,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.heaviside_(self,values)|Tensor(a!),Tensor
torch.ops.aten.hinge_embedding_loss(self,target,margin,reduction)|Tensor,Tensor,float,int
torch.ops.aten.histc(self,bins,min,max)|Tensor,int,Scalar,Scalar
torch.ops.aten.histc.out(self,bins,min,max,out)|Tensor,int,Scalar,Scalar,Tensor(a!)
torch.ops.aten.huber_loss(self,target,reduction,delta)|Tensor,Tensor,int,float
torch.ops.aten.huber_loss.out(self,target,reduction,delta,out)|Tensor,Tensor,int,float,Tensor(a!)
torch.ops.aten.huber_loss_backward.out(grad_output,self,target,reduction,delta,grad_input)|Tensor,Tensor,Tensor,int,float,Tensor(a!)
torch.ops.aten.huber_loss_backward(grad_output,self,target,reduction,delta)|Tensor,Tensor,Tensor,int,float
torch.ops.aten.hypot(self,other)|Tensor,Tensor
torch.ops.aten.hypot.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.hypot_(self,other)|Tensor(a!),Tensor
torch.ops.aten.i0(self)|Tensor
torch.ops.aten.i0.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.i0_(self)|Tensor(a!)
torch.ops.aten.igamma(self,other)|Tensor,Tensor
torch.ops.aten.igamma.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.igamma_(self,other)|Tensor(a!),Tensor
torch.ops.aten.igammac(self,other)|Tensor,Tensor
torch.ops.aten.igammac.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.igammac_(self,other)|Tensor(a!),Tensor
torch.ops.aten.im2col(self,kernel_size,dilation,padding,stride)|Tensor,int[2],int[2],int[2],int[2]
torch.ops.aten.im2col.out(self,kernel_size,dilation,padding,stride,out)|Tensor,int[2],int[2],int[2],int[2],Tensor(a!)
torch.ops.aten.imag(self)|Tensor(a)
torch.ops.aten.index.Tensor(self,indices)|Tensor,Tensor?[]
torch.ops.aten.index.Tensor_out(self,indices,out)|Tensor,Tensor?[],Tensor(a!)
torch.ops.aten.index.Tensor_hacked_twin(self,indices)|Tensor,Tensor[]
torch.ops.aten.index.str(self,substr,start,end)|str,str,int,int
torch.ops.aten.index.list_int(self,el)|int[],int
torch.ops.aten.index.list_float(self,el)|float[],float
torch.ops.aten.index.list_bool(self,el)|bool[],bool
torch.ops.aten.index.list_Tensor(self,el)|Tensor[],Tensor
torch.ops.aten.index.list_str(self,el)|str[],str
torch.ops.aten.index_add(self,dim,index,source,alpha)|Tensor,int,Tensor,Tensor,Scalar
torch.ops.aten.index_add.out(self,dim,index,source,alpha,out)|Tensor,int,Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.index_add.dimname(self,dim,index,source,alpha)|Tensor,str,Tensor,Tensor,Scalar
torch.ops.aten.index_add_(self,dim,index,source,alpha)|Tensor(a!),int,Tensor,Tensor,Scalar
torch.ops.aten.index_copy(self,dim,index,source)|Tensor,int,Tensor,Tensor
torch.ops.aten.index_copy.dimname(self,dim,index,source)|Tensor,str,Tensor,Tensor
torch.ops.aten.index_copy.out(self,dim,index,source,out)|Tensor,int,Tensor,Tensor,Tensor(a!)
torch.ops.aten.index_copy_(self,dim,index,source)|Tensor(a!),int,Tensor,Tensor
torch.ops.aten.index_copy_.dimname(self,dim,index,source)|Tensor(a!),str,Tensor,Tensor
torch.ops.aten.index_fill.int_Tensor(self,dim,index,value)|Tensor,int,Tensor,Tensor
torch.ops.aten.index_fill.int_Scalar(self,dim,index,value)|Tensor,int,Tensor,Scalar
torch.ops.aten.index_fill.Dimname_Scalar(self,dim,index,value)|Tensor,str,Tensor,Scalar
torch.ops.aten.index_fill.Dimname_Tensor(self,dim,index,value)|Tensor,str,Tensor,Tensor
torch.ops.aten.index_fill.int_Scalar_out(self,dim,index,value,out)|Tensor,int,Tensor,Scalar,Tensor(a!)
torch.ops.aten.index_fill.int_Tensor_out(self,dim,index,value,out)|Tensor,int,Tensor,Tensor,Tensor(a!)
torch.ops.aten.index_fill_.int_Tensor(self,dim,index,value)|Tensor(a!),int,Tensor,Tensor
torch.ops.aten.index_fill_.int_Scalar(self,dim,index,value)|Tensor(a!),int,Tensor,Scalar
torch.ops.aten.index_fill_.Dimname_Scalar(self,dim,index,value)|Tensor(a!),str,Tensor,Scalar
torch.ops.aten.index_fill_.Dimname_Tensor(self,dim,index,value)|Tensor(a!),str,Tensor,Tensor
torch.ops.aten.index_put(self,indices,values,accumulate)|Tensor,Tensor?[],Tensor,bool
torch.ops.aten.index_put.out(self,indices,values,accumulate,out)|Tensor,Tensor?[],Tensor,bool,Tensor(a!)
torch.ops.aten.index_put.hacked_twin(self,indices,values,accumulate)|Tensor,Tensor[],Tensor,bool
torch.ops.aten.index_put_(self,indices,values,accumulate)|Tensor(a!),Tensor?[],Tensor,bool
torch.ops.aten.index_put_.hacked_twin(self,indices,values,accumulate)|Tensor(a!),Tensor[],Tensor,bool
torch.ops.aten.index_reduce(self,dim,index,source,reduce,include_self)|Tensor,int,Tensor,Tensor,str,bool
torch.ops.aten.index_reduce.out(self,dim,index,source,reduce,include_self,out)|Tensor,int,Tensor,Tensor,str,bool,Tensor(a!)
torch.ops.aten.index_reduce_(self,dim,index,source,reduce,include_self)|Tensor(a!),int,Tensor,Tensor,str,bool
torch.ops.aten.index_select(self,dim,index)|Tensor,int,Tensor
torch.ops.aten.index_select.out(self,dim,index,out)|Tensor,int,Tensor,Tensor(a!)
torch.ops.aten.index_select.dimname(self,dim,index)|Tensor,str,Tensor
torch.ops.aten.index_select.dimname_out(self,dim,index,out)|Tensor,str,Tensor,Tensor(a!)
torch.ops.aten.is_coalesced(self)|Tensor
torch.ops.aten.is_complex(self)|Tensor
torch.ops.aten.is_contiguous(self)|Tensor
torch.ops.aten.is_contiguous.memory_format(self,memory_format)|Tensor,MemoryFormat
torch.ops.aten.is_non_overlapping_and_dense(self)|Tensor
torch.ops.aten.is_pinned(self,device)|Tensor,Device?
torch.ops.aten.is_same_size(self,other)|Tensor,Tensor
torch.ops.aten.is_strides_like_format(self,memory_format)|Tensor,MemoryFormat
torch.ops.aten.isfinite(self)|Tensor
torch.ops.aten.isfinite.float(a)|float
torch.ops.aten.isfinite.complex(a)|complex
torch.ops.aten.isin.Tensor_Tensor(elements,test_elements,assume_unique,invert)|Tensor,Tensor,bool,bool
torch.ops.aten.isin.Tensor_Tensor_out(elements,test_elements,assume_unique,invert,out)|Tensor,Tensor,bool,bool,Tensor(a!)
torch.ops.aten.isin.Tensor_Scalar(elements,test_element,assume_unique,invert)|Tensor,Scalar,bool,bool
torch.ops.aten.isin.Tensor_Scalar_out(elements,test_element,assume_unique,invert,out)|Tensor,Scalar,bool,bool,Tensor(a!)
torch.ops.aten.isin.Scalar_Tensor(element,test_elements,assume_unique,invert)|Scalar,Tensor,bool,bool
torch.ops.aten.isin.Scalar_Tensor_out(element,test_elements,assume_unique,invert,out)|Scalar,Tensor,bool,bool,Tensor(a!)
torch.ops.aten.isinf(self)|Tensor
torch.ops.aten.isinf.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.isinf.float(a)|float
torch.ops.aten.isinf.complex(a)|complex
torch.ops.aten.isnan(self)|Tensor
torch.ops.aten.isnan.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.isnan.float(a)|float
torch.ops.aten.isnan.complex(a)|complex
torch.ops.aten.isneginf(self)|Tensor
torch.ops.aten.isneginf.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.isposinf(self)|Tensor
torch.ops.aten.isposinf.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.istft(self,n_fft,hop_length,win_length,window,center,normalized,onesided,length,return_complex)|Tensor,int,int?,int?,Tensor?,bool,bool,bool?,int?,bool
torch.ops.aten.item(self)|Tensor
torch.ops.aten.kthvalue(self,k,dim,keepdim)|Tensor,int,int,bool
torch.ops.aten.kthvalue.dimname(self,k,dim,keepdim)|Tensor,int,str,bool
torch.ops.aten.kthvalue.dimname_out(self,k,dim,keepdim,values,indices)|Tensor,int,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.kthvalue.values(self,k,dim,keepdim,values,indices)|Tensor,int,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.lcm(self,other)|Tensor,Tensor
torch.ops.aten.lcm.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.lcm_(self,other)|Tensor(a!),Tensor
torch.ops.aten.le.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.le.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.le.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.le.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.le.int(a,b)|int,int
torch.ops.aten.le.float(a,b)|float,float
torch.ops.aten.le.int_float(a,b)|int,float
torch.ops.aten.le.float_int(a,b)|float,int
torch.ops.aten.le(a,b)|Scalar,Scalar
torch.ops.aten.le.str(a,b)|str,str
torch.ops.aten.le_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.le_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.leaky_relu(self,negative_slope)|Tensor,Scalar
torch.ops.aten.leaky_relu.out(self,negative_slope,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.leaky_relu_(self,negative_slope)|Tensor(a!),Scalar
torch.ops.aten.leaky_relu_backward(grad_output,self,negative_slope,self_is_result)|Tensor,Tensor,Scalar,bool
torch.ops.aten.leaky_relu_backward.grad_input(grad_output,self,negative_slope,self_is_result,grad_input)|Tensor,Tensor,Scalar,bool,Tensor(a!)
torch.ops.aten.lerp.Scalar(self,end,weight)|Tensor,Tensor,Scalar
torch.ops.aten.lerp.Tensor(self,end,weight)|Tensor,Tensor,Tensor
torch.ops.aten.lerp.Scalar_out(self,end,weight,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.lerp.Tensor_out(self,end,weight,out)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.lerp_.Scalar(self,end,weight)|Tensor(a!),Tensor,Scalar
torch.ops.aten.lerp_.Tensor(self,end,weight)|Tensor(a!),Tensor,Tensor
torch.ops.aten.less.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.less.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.less.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.less.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.less_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.less_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.less_equal.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.less_equal.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.less_equal.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.less_equal.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.less_equal_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.less_equal_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.lgamma(self)|Tensor
torch.ops.aten.lgamma.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.lgamma.int(a)|int
torch.ops.aten.lgamma.float(a)|float
torch.ops.aten.lgamma.Scalar(a)|Scalar
torch.ops.aten.lgamma_(self)|Tensor(a!)
torch.ops.aten.lift(self)|Tensor
torch.ops.aten.lift.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.lift_fresh(self)|Tensor(a)
torch.ops.aten.lift_fresh_copy(self)|Tensor
torch.ops.aten.lift_fresh_copy.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.linalg_cholesky_ex(self,upper,check_errors)|Tensor,bool,bool
torch.ops.aten.linalg_cholesky_ex.L(self,upper,check_errors,L,info)|Tensor,bool,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.linalg_cross(self,other,dim)|Tensor,Tensor,int
torch.ops.aten.linalg_cross.out(self,other,dim,out)|Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.linalg_eig(self)|Tensor
torch.ops.aten.linalg_eig.out(self,eigenvalues,eigenvectors)|Tensor,Tensor(a!),Tensor(b!)
torch.ops.aten.linalg_eigvals(self)|Tensor
torch.ops.aten.linalg_eigvals.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.linalg_householder_product(input,tau)|Tensor,Tensor
torch.ops.aten.linalg_householder_product.out(input,tau,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.linalg_inv_ex(A,check_errors)|Tensor,bool
torch.ops.aten.linalg_inv_ex.inverse(A,check_errors,inverse,info)|Tensor,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.linalg_ldl_factor_ex(self,hermitian,check_errors)|Tensor,bool,bool
torch.ops.aten.linalg_ldl_factor_ex.out(self,hermitian,check_errors,LD,pivots,info)|Tensor,bool,bool,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.linalg_ldl_solve(LD,pivots,B,hermitian)|Tensor,Tensor,Tensor,bool
torch.ops.aten.linalg_ldl_solve.out(LD,pivots,B,hermitian,out)|Tensor,Tensor,Tensor,bool,Tensor(a!)
torch.ops.aten.linalg_lu(A,pivot)|Tensor,bool
torch.ops.aten.linalg_lu.out(A,pivot,P,L,U)|Tensor,bool,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.linalg_lu_factor_ex(A,pivot,check_errors)|Tensor,bool,bool
torch.ops.aten.linalg_lu_factor_ex.out(A,pivot,check_errors,LU,pivots,info)|Tensor,bool,bool,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.linalg_lu_solve(LU,pivots,B,left,adjoint)|Tensor,Tensor,Tensor,bool,bool
torch.ops.aten.linalg_lu_solve.out(LU,pivots,B,left,adjoint,out)|Tensor,Tensor,Tensor,bool,bool,Tensor(a!)
torch.ops.aten.linalg_matrix_exp(self)|Tensor
torch.ops.aten.linalg_matrix_exp.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.linalg_qr(A,mode)|Tensor,str
torch.ops.aten.linalg_qr.out(A,mode,Q,R)|Tensor,str,Tensor(a!),Tensor(b!)
torch.ops.aten.linalg_solve_triangular(self,B,upper,left,unitriangular)|Tensor,Tensor,bool,bool,bool
torch.ops.aten.linalg_solve_triangular.out(self,B,upper,left,unitriangular,out)|Tensor,Tensor,bool,bool,bool,Tensor(a!)
torch.ops.aten.linalg_vector_norm(self,ord,dim,keepdim,dtype)|Tensor,Scalar,int[1]?,bool,ScalarType?
torch.ops.aten.linalg_vector_norm.out(self,ord,dim,keepdim,dtype,out)|Tensor,Scalar,int[1]?,bool,ScalarType?,Tensor(a!)
torch.ops.aten.linear(input,weight,bias)|Tensor,Tensor,Tensor?
torch.ops.aten.linear.out(input,weight,bias,out)|Tensor,Tensor,Tensor?,Tensor(a!)
torch.ops.aten.linear_backward.out(self,grad_output,weight,output_mask,out0,out1,out2)|Tensor,Tensor,Tensor,bool[3],Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.linear_backward(self,grad_output,weight,output_mask)|Tensor,Tensor,Tensor,bool[3]
torch.ops.aten.linspace.Tensor_Tensor(start,end,steps,dtype,layout,device,pin_memory)|Tensor,Tensor,int,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.linspace.Tensor_Scalar(start,end,steps,dtype,layout,device,pin_memory)|Tensor,Scalar,int,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.linspace.Scalar_Tensor(start,end,steps,dtype,layout,device,pin_memory)|Scalar,Tensor,int,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.linspace(start,end,steps,dtype,layout,device,pin_memory)|Scalar,Scalar,int,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.linspace.out(start,end,steps,out)|Scalar,Scalar,int,Tensor(a!)
torch.ops.aten.linspace.Tensor_Tensor_out(start,end,steps,out)|Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.linspace.Tensor_Scalar_out(start,end,steps,out)|Tensor,Scalar,int,Tensor(a!)
torch.ops.aten.linspace.Scalar_Tensor_out(start,end,steps,out)|Scalar,Tensor,int,Tensor(a!)
torch.ops.aten.log(self)|Tensor
torch.ops.aten.log.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.log.int(a)|int
torch.ops.aten.log.float(a)|float
torch.ops.aten.log.complex(a)|complex
torch.ops.aten.log.Scalar(a)|Scalar
torch.ops.aten.log.int_int(a,b)|int,int
torch.ops.aten.log.float_float(a,b)|float,float
torch.ops.aten.log.complex_complex(a,b)|complex,complex
torch.ops.aten.log.int_float(a,b)|int,float
torch.ops.aten.log.float_int(a,b)|float,int
torch.ops.aten.log.int_complex(a,b)|int,complex
torch.ops.aten.log.complex_int(a,b)|complex,int
torch.ops.aten.log.float_complex(a,b)|float,complex
torch.ops.aten.log.complex_float(a,b)|complex,float
torch.ops.aten.log.Scalar_Scalar(a,b)|Scalar,Scalar
torch.ops.aten.log10(self)|Tensor
torch.ops.aten.log10.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.log10.int(a)|int
torch.ops.aten.log10.float(a)|float
torch.ops.aten.log10.complex(a)|complex
torch.ops.aten.log10.Scalar(a)|Scalar
torch.ops.aten.log10_(self)|Tensor(a!)
torch.ops.aten.log1p(self)|Tensor
torch.ops.aten.log1p.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.log1p.int(a)|int
torch.ops.aten.log1p.float(a)|float
torch.ops.aten.log1p.Scalar(a)|Scalar
torch.ops.aten.log1p_(self)|Tensor(a!)
torch.ops.aten.log2(self)|Tensor
torch.ops.aten.log2.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.log2_(self)|Tensor(a!)
torch.ops.aten.log_(self)|Tensor(a!)
torch.ops.aten.log_normal(self,mean,std,generator)|Tensor,float,float,Generator?
torch.ops.aten.log_normal.out(self,mean,std,generator,out)|Tensor,float,float,Generator?,Tensor(a!)
torch.ops.aten.log_normal_(self,mean,std,generator)|Tensor(a!),float,float,Generator?
torch.ops.aten.log_sigmoid_backward(grad_output,self,buffer)|Tensor,Tensor,Tensor
torch.ops.aten.log_sigmoid_backward.grad_input(grad_output,self,buffer,grad_input)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.log_sigmoid_forward(self)|Tensor
torch.ops.aten.log_sigmoid_forward.output(self,output,buffer)|Tensor,Tensor(a!),Tensor(b!)
torch.ops.aten.logaddexp(self,other)|Tensor,Tensor
torch.ops.aten.logaddexp.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.logaddexp2(self,other)|Tensor,Tensor
torch.ops.aten.logaddexp2.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.logcumsumexp(self,dim)|Tensor,int
torch.ops.aten.logcumsumexp.dimname(self,dim)|Tensor,str
torch.ops.aten.logcumsumexp.dimname_out(self,dim,out)|Tensor,str,Tensor(a!)
torch.ops.aten.logcumsumexp.out(self,dim,out)|Tensor,int,Tensor(a!)
torch.ops.aten.logical_and(self,other)|Tensor,Tensor
torch.ops.aten.logical_and.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.logical_and_(self,other)|Tensor(a!),Tensor
torch.ops.aten.logical_not(self)|Tensor
torch.ops.aten.logical_not.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.logical_not_(self)|Tensor(a!)
torch.ops.aten.logical_or(self,other)|Tensor,Tensor
torch.ops.aten.logical_or.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.logical_or_(self,other)|Tensor(a!),Tensor
torch.ops.aten.logical_xor(self,other)|Tensor,Tensor
torch.ops.aten.logical_xor.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.logical_xor_(self,other)|Tensor(a!),Tensor
torch.ops.aten.logit(self,eps)|Tensor,float?
torch.ops.aten.logit.out(self,eps,out)|Tensor,float?,Tensor(a!)
torch.ops.aten.logit_(self,eps)|Tensor(a!),float?
torch.ops.aten.logit_backward(grad_output,self,eps)|Tensor,Tensor,float?
torch.ops.aten.logit_backward.grad_input(grad_output,self,eps,grad_input)|Tensor,Tensor,float?,Tensor(a!)
torch.ops.aten.logspace.Tensor_Tensor(start,end,steps,base,dtype,layout,device,pin_memory)|Tensor,Tensor,int,float,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.logspace.Tensor_Scalar(start,end,steps,base,dtype,layout,device,pin_memory)|Tensor,Scalar,int,float,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.logspace.Scalar_Tensor(start,end,steps,base,dtype,layout,device,pin_memory)|Scalar,Tensor,int,float,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.logspace(start,end,steps,base,dtype,layout,device,pin_memory)|Scalar,Scalar,int,float,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.logspace.out(start,end,steps,base,out)|Scalar,Scalar,int,float,Tensor(a!)
torch.ops.aten.logspace.Tensor_Tensor_out(start,end,steps,base,out)|Tensor,Tensor,int,float,Tensor(a!)
torch.ops.aten.logspace.Tensor_Scalar_out(start,end,steps,base,out)|Tensor,Scalar,int,float,Tensor(a!)
torch.ops.aten.logspace.Scalar_Tensor_out(start,end,steps,base,out)|Scalar,Tensor,int,float,Tensor(a!)
torch.ops.aten.logsumexp(self,dim,keepdim)|Tensor,int[1],bool
torch.ops.aten.logsumexp.names(self,dim,keepdim)|Tensor,str[1],bool
torch.ops.aten.logsumexp.names_out(self,dim,keepdim,out)|Tensor,str[1],bool,Tensor(a!)
torch.ops.aten.logsumexp.out(self,dim,keepdim,out)|Tensor,int[1],bool,Tensor(a!)
torch.ops.aten.lstm.input(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first)|Tensor,Tensor[],Tensor[],bool,int,float,bool,bool,bool
torch.ops.aten.lstm.data(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional)|Tensor,Tensor,Tensor[],Tensor[],bool,int,float,bool,bool
torch.ops.aten.lt.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.lt.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.lt.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.lt.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.lt.int(a,b)|int,int
torch.ops.aten.lt.float(a,b)|float,float
torch.ops.aten.lt.int_float(a,b)|int,float
torch.ops.aten.lt.float_int(a,b)|float,int
torch.ops.aten.lt(a,b)|Scalar,Scalar
torch.ops.aten.lt.str(a,b)|str,str
torch.ops.aten.lt_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.lt_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.lu_unpack(LU_data,LU_pivots,unpack_data,unpack_pivots)|Tensor,Tensor,bool,bool
torch.ops.aten.lu_unpack.out(LU_data,LU_pivots,unpack_data,unpack_pivots,P,L,U)|Tensor,Tensor,bool,bool,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.margin_ranking_loss(input1,input2,target,margin,reduction)|Tensor,Tensor,Tensor,float,int
torch.ops.aten.masked_fill.Scalar(self,mask,value)|Tensor,Tensor,Scalar
torch.ops.aten.masked_fill.Tensor(self,mask,value)|Tensor,Tensor,Tensor
torch.ops.aten.masked_fill.Scalar_out(self,mask,value,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.masked_fill.Tensor_out(self,mask,value,out)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.masked_fill_.Scalar(self,mask,value)|Tensor(a!),Tensor,Scalar
torch.ops.aten.masked_fill_.Tensor(self,mask,value)|Tensor(a!),Tensor,Tensor
torch.ops.aten.masked_scatter(self,mask,source)|Tensor,Tensor,Tensor
torch.ops.aten.masked_scatter.out(self,mask,source,out)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.masked_scatter_(self,mask,source)|Tensor(a!),Tensor,Tensor
torch.ops.aten.masked_scatter_backward(grad_output,mask,sizes)|Tensor,Tensor,SymInt[]
torch.ops.aten.masked_select(self,mask)|Tensor,Tensor
torch.ops.aten.masked_select.out(self,mask,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.matmul(self,other)|Tensor,Tensor
torch.ops.aten.matmul.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.max.other(self,other)|Tensor,Tensor
torch.ops.aten.max(self)|Tensor
torch.ops.aten.max.dim(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.max.dim_max(self,dim,keepdim,max,max_values)|Tensor,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.max.names_dim(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.max.names_dim_max(self,dim,keepdim,max,max_values)|Tensor,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.max.unary_out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.max.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.max_pool2d_with_indices(self,kernel_size,stride,padding,dilation,ceil_mode)|Tensor,int[2],int[2],int[2],int[2],bool
torch.ops.aten.max_pool2d_with_indices.out(self,kernel_size,stride,padding,dilation,ceil_mode,out,indices)|Tensor,int[2],int[2],int[2],int[2],bool,Tensor(a!),Tensor(b!)
torch.ops.aten.max_pool2d_with_indices_backward(grad_output,self,kernel_size,stride,padding,dilation,ceil_mode,indices)|Tensor,Tensor,int[2],int[2],int[2],int[2],bool,Tensor
torch.ops.aten.max_pool2d_with_indices_backward.grad_input(grad_output,self,kernel_size,stride,padding,dilation,ceil_mode,indices,grad_input)|Tensor,Tensor,int[2],int[2],int[2],int[2],bool,Tensor,Tensor(a!)
torch.ops.aten.max_pool3d_with_indices(self,kernel_size,stride,padding,dilation,ceil_mode)|Tensor,int[3],int[3],int[3],int[3],bool
torch.ops.aten.max_pool3d_with_indices.out(self,kernel_size,stride,padding,dilation,ceil_mode,out,indices)|Tensor,int[3],int[3],int[3],int[3],bool,Tensor(a!),Tensor(b!)
torch.ops.aten.max_pool3d_with_indices_backward(grad_output,self,kernel_size,stride,padding,dilation,ceil_mode,indices)|Tensor,Tensor,int[3],int[3],int[3],int[3],bool,Tensor
torch.ops.aten.max_pool3d_with_indices_backward.grad_input(grad_output,self,kernel_size,stride,padding,dilation,ceil_mode,indices,grad_input)|Tensor,Tensor,int[3],int[3],int[3],int[3],bool,Tensor,Tensor(a!)
torch.ops.aten.max_unpool2d(self,indices,output_size)|Tensor,Tensor,SymInt[2]
torch.ops.aten.max_unpool2d.out(self,indices,output_size,out)|Tensor,Tensor,SymInt[2],Tensor(a!)
torch.ops.aten.max_unpool3d(self,indices,output_size,stride,padding)|Tensor,Tensor,SymInt[3],int[3],int[3]
torch.ops.aten.max_unpool3d.out(self,indices,output_size,stride,padding,out)|Tensor,Tensor,SymInt[3],int[3],int[3],Tensor(a!)
torch.ops.aten.maximum(self,other)|Tensor,Tensor
torch.ops.aten.maximum.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.mean(self,dtype)|Tensor,ScalarType?
torch.ops.aten.mean.dim(self,dim,keepdim,dtype)|Tensor,int[1]?,bool,ScalarType?
torch.ops.aten.mean.names_dim(self,dim,keepdim,dtype)|Tensor,str[1],bool,ScalarType?
torch.ops.aten.mean.names_out(self,dim,keepdim,dtype,out)|Tensor,str[1],bool,ScalarType?,Tensor(a!)
torch.ops.aten.mean.out(self,dim,keepdim,dtype,out)|Tensor,int[1]?,bool,ScalarType?,Tensor(a!)
torch.ops.aten.mean.dtype_out(self,dtype,out)|Tensor,ScalarType?,Tensor(a!)
torch.ops.aten.median(self)|Tensor
torch.ops.aten.median.dim(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.median.dim_values(self,dim,keepdim,values,indices)|Tensor,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.median.names_dim(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.median.names_dim_values(self,dim,keepdim,values,indices)|Tensor,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.median.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.meshgrid(tensors)|Tensor[]
torch.ops.aten.meshgrid.indexing(tensors,indexing)|Tensor[],str
torch.ops.aten.min.other(self,other)|Tensor,Tensor
torch.ops.aten.min(self)|Tensor
torch.ops.aten.min.dim(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.min.dim_min(self,dim,keepdim,min,min_indices)|Tensor,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.min.names_dim(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.min.names_dim_min(self,dim,keepdim,min,min_indices)|Tensor,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.min.unary_out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.min.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.minimum(self,other)|Tensor,Tensor
torch.ops.aten.minimum.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.miopen_batch_norm(input,weight,bias,running_mean,running_var,training,exponential_average_factor,epsilon)|Tensor,Tensor,Tensor?,Tensor?,Tensor?,bool,float,float
torch.ops.aten.miopen_batch_norm.out(input,weight,bias,running_mean,running_var,training,exponential_average_factor,epsilon,out0,out1,out2)|Tensor,Tensor,Tensor?,Tensor?,Tensor?,bool,float,float,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.miopen_batch_norm_backward(input,grad_output,weight,running_mean,running_var,save_mean,save_var,epsilon)|Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,float
torch.ops.aten.miopen_batch_norm_backward.out(input,grad_output,weight,running_mean,running_var,save_mean,save_var,epsilon,out0,out1,out2)|Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,float,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.mish(self)|Tensor
torch.ops.aten.mish.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.mish_(self)|Tensor(a!)
torch.ops.aten.mish_backward(grad_output,self)|Tensor,Tensor
torch.ops.aten.mkldnn_rnn_layer(input,weight0,weight1,weight2,weight3,hx_,cx_,reverse,batch_sizes,mode,hidden_size,num_layers,has_biases,bidirectional,batch_first,train)|Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,bool,int[],int,int,int,bool,bool,bool,bool
torch.ops.aten.mkldnn_rnn_layer.out(input,weight0,weight1,weight2,weight3,hx_,cx_,reverse,batch_sizes,mode,hidden_size,num_layers,has_biases,bidirectional,batch_first,train,out0,out1,out2,out3)|Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,bool,int[],int,int,int,bool,bool,bool,bool,Tensor(a!),Tensor(b!),Tensor(c!),Tensor(d!)
torch.ops.aten.mkldnn_rnn_layer_backward(input,weight1,weight2,weight3,weight4,hx_,cx_tmp,output,hy_,cy_,grad_output,grad_hy,grad_cy,reverse,mode,hidden_size,num_layers,has_biases,train,bidirectional,batch_sizes,batch_first,workspace)|Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,bool,int,int,int,bool,bool,bool,int[],bool,Tensor
torch.ops.aten.mkldnn_rnn_layer_backward.out(input,weight1,weight2,weight3,weight4,hx_,cx_tmp,output,hy_,cy_,grad_output,grad_hy,grad_cy,reverse,mode,hidden_size,num_layers,has_biases,train,bidirectional,batch_sizes,batch_first,workspace,out0,out1,out2,out3,out4,out5,out6)|Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor,Tensor?,Tensor?,Tensor?,bool,int,int,int,bool,bool,bool,int[],bool,Tensor,Tensor(a!),Tensor(b!),Tensor(c!),Tensor(d!),Tensor(e!),Tensor(f!),Tensor(g!)
torch.ops.aten.mm(self,mat2)|Tensor,Tensor
torch.ops.aten.mm.out(self,mat2,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.mode(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.mode.dimname(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.mode.dimname_out(self,dim,keepdim,values,indices)|Tensor,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.mode.values(self,dim,keepdim,values,indices)|Tensor,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.mse_loss(self,target,reduction)|Tensor,Tensor,int
torch.ops.aten.mse_loss.out(self,target,reduction,out)|Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.mse_loss_backward(grad_output,self,target,reduction)|Tensor,Tensor,Tensor,int
torch.ops.aten.mse_loss_backward.grad_input(grad_output,self,target,reduction,grad_input)|Tensor,Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.mul.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.mul.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.mul.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.mul.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.mul.left_t(l,n)|t[],int
torch.ops.aten.mul.right_(n,l)|int,t[]
torch.ops.aten.mul.int(a,b)|int,int
torch.ops.aten.mul.complex(a,b)|complex,complex
torch.ops.aten.mul.float(a,b)|float,float
torch.ops.aten.mul.int_complex(a,b)|int,complex
torch.ops.aten.mul.complex_int(a,b)|complex,int
torch.ops.aten.mul.float_complex(a,b)|float,complex
torch.ops.aten.mul.complex_float(a,b)|complex,float
torch.ops.aten.mul.int_float(a,b)|int,float
torch.ops.aten.mul.float_int(a,b)|float,int
torch.ops.aten.mul(a,b)|Scalar,Scalar
torch.ops.aten.mul_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.mul_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.mul_.t(l,n)|t[](a!),int
torch.ops.aten.multi_margin_loss(self,target,p,margin,weight,reduction)|Tensor,Tensor,Scalar,Scalar,Tensor?,int
torch.ops.aten.multi_margin_loss.out(self,target,p,margin,weight,reduction,out)|Tensor,Tensor,Scalar,Scalar,Tensor?,int,Tensor(a!)
torch.ops.aten.multilabel_margin_loss_forward(self,target,reduction)|Tensor,Tensor,int
torch.ops.aten.multilabel_margin_loss_forward.output(self,target,reduction,output,is_target)|Tensor,Tensor,int,Tensor(a!),Tensor(b!)
torch.ops.aten.multinomial(self,num_samples,replacement,generator)|Tensor,int,bool,Generator?
torch.ops.aten.multinomial.out(self,num_samples,replacement,generator,out)|Tensor,int,bool,Generator?,Tensor(a!)
torch.ops.aten.multiply.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.multiply.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.multiply.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.multiply_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.multiply_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.mv(self,vec)|Tensor,Tensor
torch.ops.aten.mv.out(self,vec,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.mvlgamma(self,p)|Tensor,int
torch.ops.aten.mvlgamma.out(self,p,out)|Tensor,int,Tensor(a!)
torch.ops.aten.mvlgamma_(self,p)|Tensor(a!),int
torch.ops.aten.nan_to_num(self,nan,posinf,neginf)|Tensor,float?,float?,float?
torch.ops.aten.nan_to_num.out(self,nan,posinf,neginf,out)|Tensor,float?,float?,float?,Tensor(a!)
torch.ops.aten.nan_to_num_(self,nan,posinf,neginf)|Tensor(a!),float?,float?,float?
torch.ops.aten.nanmedian(self)|Tensor
torch.ops.aten.nanmedian.dim(self,dim,keepdim)|Tensor,int,bool
torch.ops.aten.nanmedian.dim_values(self,dim,keepdim,values,indices)|Tensor,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.nanmedian.names_dim(self,dim,keepdim)|Tensor,str,bool
torch.ops.aten.nanmedian.names_dim_values(self,dim,keepdim,values,indices)|Tensor,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.nanmedian.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.nansum(self,dim,keepdim,dtype)|Tensor,int[1]?,bool,ScalarType?
torch.ops.aten.nansum.out(self,dim,keepdim,dtype,out)|Tensor,int[1]?,bool,ScalarType?,Tensor(a!)
torch.ops.aten.narrow(self,dim,start,length)|Tensor(a),int,SymInt,SymInt
torch.ops.aten.narrow.Tensor(self,dim,start,length)|Tensor(a),int,Tensor,SymInt
torch.ops.aten.narrow_copy(self,dim,start,length)|Tensor,int,SymInt,SymInt
torch.ops.aten.narrow_copy.out(self,dim,start,length,out)|Tensor,int,SymInt,SymInt,Tensor(a!)
torch.ops.aten.native_batch_norm(input,weight,bias,running_mean,running_var,training,momentum,eps)|Tensor,Tensor?,Tensor?,Tensor?,Tensor?,bool,float,float
torch.ops.aten.native_batch_norm.out(input,weight,bias,running_mean,running_var,training,momentum,eps,out,save_mean,save_invstd)|Tensor,Tensor?,Tensor?,Tensor?,Tensor?,bool,float,float,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.native_batch_norm_backward(grad_out,input,weight,running_mean,running_var,save_mean,save_invstd,train,eps,output_mask)|Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,Tensor?,bool,float,bool[3]
torch.ops.aten.native_batch_norm_backward.out(grad_out,input,weight,running_mean,running_var,save_mean,save_invstd,train,eps,output_mask,out0,out1,out2)|Tensor,Tensor,Tensor?,Tensor?,Tensor?,Tensor?,Tensor?,bool,float,bool[3],Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.native_dropout(input,p,train)|Tensor,float,bool?
torch.ops.aten.native_dropout.out(input,p,train,out0,out1)|Tensor,float,bool?,Tensor(a!),Tensor(b!)
torch.ops.aten.native_dropout_backward(grad_output,mask,scale)|Tensor,Tensor,float
torch.ops.aten.native_dropout_backward.out(grad_output,mask,scale,out)|Tensor,Tensor,float,Tensor(a!)
torch.ops.aten.native_group_norm(input,weight,bias,N,C,HxW,group,eps)|Tensor,Tensor?,Tensor?,SymInt,SymInt,SymInt,int,float
torch.ops.aten.native_group_norm.out(input,weight,bias,N,C,HxW,group,eps,out0,out1,out2)|Tensor,Tensor?,Tensor?,SymInt,SymInt,SymInt,int,float,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.native_group_norm_backward(grad_out,input,mean,rstd,weight,N,C,HxW,group,output_mask)|Tensor,Tensor,Tensor,Tensor,Tensor?,SymInt,SymInt,SymInt,int,bool[3]
torch.ops.aten.native_group_norm_backward.out(grad_out,input,mean,rstd,weight,N,C,HxW,group,output_mask,out0,out1,out2)|Tensor,Tensor,Tensor,Tensor,Tensor?,SymInt,SymInt,SymInt,int,bool[3],Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.native_layer_norm(input,normalized_shape,weight,bias,eps)|Tensor,SymInt[],Tensor?,Tensor?,float
torch.ops.aten.native_layer_norm.out(input,normalized_shape,weight,bias,eps,out0,out1,out2)|Tensor,SymInt[],Tensor?,Tensor?,float,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.native_layer_norm_backward(grad_out,input,normalized_shape,mean,rstd,weight,bias,output_mask)|Tensor,Tensor,SymInt[],Tensor,Tensor,Tensor?,Tensor?,bool[3]
torch.ops.aten.native_layer_norm_backward.out(grad_out,input,normalized_shape,mean,rstd,weight,bias,output_mask,out0,out1,out2)|Tensor,Tensor,SymInt[],Tensor,Tensor,Tensor?,Tensor?,bool[3],Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.ne.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.ne.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.ne.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.ne.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.ne.int_list(a,b)|int[],int[]
torch.ops.aten.ne.device(a,b)|Device,Device
torch.ops.aten.ne.bool(a,b)|bool,bool
torch.ops.aten.ne.enum(a,b)|AnyEnumType,AnyEnumType
torch.ops.aten.ne.int(a,b)|int,int
torch.ops.aten.ne.complex(a,b)|complex,complex
torch.ops.aten.ne.float(a,b)|float,float
torch.ops.aten.ne.int_float(a,b)|int,float
torch.ops.aten.ne.float_int(a,b)|float,int
torch.ops.aten.ne.float_complex(a,b)|float,complex
torch.ops.aten.ne.complex_float(a,b)|complex,float
torch.ops.aten.ne(a,b)|Scalar,Scalar
torch.ops.aten.ne.str(a,b)|str,str
torch.ops.aten.ne.float_list(a,b)|float[],float[]
torch.ops.aten.ne.Tensor_list(a,b)|Tensor[],Tensor[]
torch.ops.aten.ne.bool_list(a,b)|bool[],bool[]
torch.ops.aten.ne.str_list(a,b)|str[],str[]
torch.ops.aten.ne_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.ne_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.neg(self)|Tensor
torch.ops.aten.neg.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.neg.int(a)|int
torch.ops.aten.neg.float(a)|float
torch.ops.aten.neg.complex(a)|complex
torch.ops.aten.neg.Scalar(a)|Scalar
torch.ops.aten.neg_(self)|Tensor(a!)
torch.ops.aten.negative(self)|Tensor
torch.ops.aten.negative.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.negative_(self)|Tensor(a!)
torch.ops.aten.new_empty(self,size,dtype,layout,device,pin_memory)|Tensor,SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.new_empty.out(self,size,out)|Tensor,SymInt[],Tensor(a!)
torch.ops.aten.new_empty_strided(self,size,stride,dtype,layout,device,pin_memory)|Tensor,SymInt[],SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.new_empty_strided.out(self,size,stride,out)|Tensor,SymInt[],SymInt[],Tensor(a!)
torch.ops.aten.new_full(self,size,fill_value,dtype,layout,device,pin_memory)|Tensor,SymInt[],Scalar,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.new_full.out(self,size,fill_value,out)|Tensor,SymInt[],Scalar,Tensor(a!)
torch.ops.aten.new_ones(self,size,dtype,layout,device,pin_memory)|Tensor,SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.new_ones.out(self,size,out)|Tensor,SymInt[],Tensor(a!)
torch.ops.aten.new_zeros(self,size,dtype,layout,device,pin_memory)|Tensor,SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.new_zeros.out(self,size,out)|Tensor,SymInt[],Tensor(a!)
torch.ops.aten.nextafter(self,other)|Tensor,Tensor
torch.ops.aten.nextafter.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.nextafter_(self,other)|Tensor(a!),Tensor
torch.ops.aten.nll_loss(self,target,weight,reduction,ignore_index)|Tensor,Tensor,Tensor?,int,SymInt
torch.ops.aten.nll_loss.out(self,target,weight,reduction,ignore_index,out)|Tensor,Tensor,Tensor?,int,SymInt,Tensor(a!)
torch.ops.aten.nll_loss2d_backward(grad_output,self,target,weight,reduction,ignore_index,total_weight)|Tensor,Tensor,Tensor,Tensor?,int,SymInt,Tensor
torch.ops.aten.nll_loss2d_backward.grad_input(grad_output,self,target,weight,reduction,ignore_index,total_weight,grad_input)|Tensor,Tensor,Tensor,Tensor?,int,SymInt,Tensor,Tensor(a!)
torch.ops.aten.nll_loss2d_forward(self,target,weight,reduction,ignore_index)|Tensor,Tensor,Tensor?,int,SymInt
torch.ops.aten.nll_loss2d_forward.output(self,target,weight,reduction,ignore_index,output,total_weight)|Tensor,Tensor,Tensor?,int,SymInt,Tensor(a!),Tensor(b!)
torch.ops.aten.nll_loss_backward(grad_output,self,target,weight,reduction,ignore_index,total_weight)|Tensor,Tensor,Tensor,Tensor?,int,SymInt,Tensor
torch.ops.aten.nll_loss_backward.grad_input(grad_output,self,target,weight,reduction,ignore_index,total_weight,grad_input)|Tensor,Tensor,Tensor,Tensor?,int,SymInt,Tensor,Tensor(a!)
torch.ops.aten.nll_loss_forward(self,target,weight,reduction,ignore_index)|Tensor,Tensor,Tensor?,int,SymInt
torch.ops.aten.nll_loss_forward.output(self,target,weight,reduction,ignore_index,output,total_weight)|Tensor,Tensor,Tensor?,int,SymInt,Tensor(a!),Tensor(b!)
torch.ops.aten.nonzero(self)|Tensor
torch.ops.aten.nonzero.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.nonzero_static(self,size,fill_value)|Tensor,int,int
torch.ops.aten.nonzero_static.out(self,size,fill_value,out)|Tensor,int,int,Tensor(a!)
torch.ops.aten.norm.Scalar(self,p)|Tensor,Scalar
torch.ops.aten.norm.ScalarOpt_dim(self,p,dim,keepdim)|Tensor,Scalar?,int[1],bool
torch.ops.aten.norm.names_ScalarOpt_dim(self,p,dim,keepdim)|Tensor,Scalar?,str[1],bool
torch.ops.aten.norm.ScalarOpt_dim_dtype(self,p,dim,keepdim,dtype)|Tensor,Scalar?,int[1],bool,ScalarType
torch.ops.aten.norm.dtype_out(self,p,dim,keepdim,dtype,out)|Tensor,Scalar?,int[1],bool,ScalarType,Tensor(a!)
torch.ops.aten.norm.out(self,p,dim,keepdim,out)|Tensor,Scalar?,int[1],bool,Tensor(a!)
torch.ops.aten.norm.ScalarOpt_dtype(self,p,dtype)|Tensor,Scalar?,ScalarType
torch.ops.aten.norm.ScalarOpt_dtype_out(self,p,dtype,out)|Tensor,Scalar?,ScalarType,Tensor(a!)
torch.ops.aten.norm.Scalar_out(self,p,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.norm.names_ScalarOpt_dim_dtype(self,p,dim,keepdim,dtype)|Tensor,Scalar?,str[1],bool,ScalarType
torch.ops.aten.norm.names_dtype_out(self,p,dim,keepdim,dtype,out)|Tensor,Scalar?,str[1],bool,ScalarType,Tensor(a!)
torch.ops.aten.norm.names_out(self,p,dim,keepdim,out)|Tensor,Scalar?,str[1],bool,Tensor(a!)
torch.ops.aten.normal.Tensor_float(mean,std,generator)|Tensor,float,Generator?
torch.ops.aten.normal.Tensor_float_out(mean,std,generator,out)|Tensor,float,Generator?,Tensor(a!)
torch.ops.aten.normal.float_Tensor_out(mean,std,generator,out)|float,Tensor,Generator?,Tensor(a!)
torch.ops.aten.normal.float_Tensor(mean,std,generator)|float,Tensor,Generator?
torch.ops.aten.normal.Tensor_Tensor(mean,std,generator)|Tensor,Tensor,Generator?
torch.ops.aten.normal.Tensor_Tensor_out(mean,std,generator,out)|Tensor,Tensor,Generator?,Tensor(a!)
torch.ops.aten.normal.float_float(mean,std,size,generator,dtype,layout,device,pin_memory)|float,float,SymInt[],Generator?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.normal.float_float_out(mean,std,size,generator,out)|float,float,SymInt[],Generator?,Tensor(a!)
torch.ops.aten.normal.out(self,mean,std,generator,out)|Tensor,float,float,Generator?,Tensor(a!)
torch.ops.aten.normal_(self,mean,std,generator)|Tensor(a!),float,float,Generator?
torch.ops.aten.not_equal.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.not_equal.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.not_equal.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.not_equal.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.not_equal_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.not_equal_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.numel(self)|Tensor
torch.ops.aten.ones.names(size,names,dtype,layout,device,pin_memory)|int[],str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.ones(size,dtype,layout,device,pin_memory)|SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.ones.names_out(size,names,out)|int[],str[]?,Tensor(a!)
torch.ops.aten.ones.out(size,out)|SymInt[],Tensor(a!)
torch.ops.aten.ones_like(self,dtype,layout,device,pin_memory,memory_format)|Tensor,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.ones_like.out(self,memory_format,out)|Tensor,MemoryFormat?,Tensor(a!)
torch.ops.aten.ormqr(self,input2,input3,left,transpose)|Tensor,Tensor,Tensor,bool,bool
torch.ops.aten.ormqr.out(self,input2,input3,left,transpose,out)|Tensor,Tensor,Tensor,bool,bool,Tensor(a!)
torch.ops.aten.pad_sequence(sequences,batch_first,padding_value,padding_side)|Tensor[],bool,float,str
torch.ops.aten.pairwise_distance(x1,x2,p,eps,keepdim)|Tensor,Tensor,float,float,bool
torch.ops.aten.pdist(self,p)|Tensor,float
torch.ops.aten.permute(self,dims)|Tensor(a),int[]
torch.ops.aten.pin_memory(self,device)|Tensor(a),Device?
torch.ops.aten.pixel_shuffle(self,upscale_factor)|Tensor,int
torch.ops.aten.pixel_shuffle.out(self,upscale_factor,out)|Tensor,int,Tensor(a!)
torch.ops.aten.pixel_unshuffle(self,downscale_factor)|Tensor,int
torch.ops.aten.pixel_unshuffle.out(self,downscale_factor,out)|Tensor,int,Tensor(a!)
torch.ops.aten.poisson(self,generator)|Tensor,Generator?
torch.ops.aten.poisson.out(self,generator,out)|Tensor,Generator?,Tensor(a!)
torch.ops.aten.polar(abs,angle)|Tensor,Tensor
torch.ops.aten.polar.out(abs,angle,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.polar.int(a,b)|int,int
torch.ops.aten.polar.float(a,b)|float,float
torch.ops.aten.polar.int_float(a,b)|int,float
torch.ops.aten.polar.float_int(a,b)|float,int
torch.ops.aten.polar.Scalar_Scalar(a,b)|Scalar,Scalar
torch.ops.aten.polygamma(n,self)|int,Tensor
torch.ops.aten.polygamma.out(n,self,out)|int,Tensor,Tensor(a!)
torch.ops.aten.positive(self)|Tensor(a)
torch.ops.aten.pow.Tensor_Tensor(self,exponent)|Tensor,Tensor
torch.ops.aten.pow.Tensor_Scalar(self,exponent)|Tensor,Scalar
torch.ops.aten.pow.Scalar(self,exponent)|Scalar,Tensor
torch.ops.aten.pow.Scalar_out(self,exponent,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.pow.Tensor_Scalar_out(self,exponent,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.pow.Tensor_Tensor_out(self,exponent,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.pow.int(a,b)|int,int
torch.ops.aten.pow.complex(a,b)|complex,complex
torch.ops.aten.pow.float(a,b)|float,float
torch.ops.aten.pow.int_float(a,b)|int,float
torch.ops.aten.pow.float_int(a,b)|float,int
torch.ops.aten.pow.float_complex(a,b)|float,complex
torch.ops.aten.pow.complex_float(a,b)|complex,float
torch.ops.aten.pow.Scalar_Scalar(a,b)|Scalar,Scalar
torch.ops.aten.pow.int_to_int(a,b)|int,int
torch.ops.aten.pow_.Scalar(self,exponent)|Tensor(a!),Scalar
torch.ops.aten.pow_.Tensor(self,exponent)|Tensor(a!),Tensor
torch.ops.aten.prelu(self,weight)|Tensor,Tensor
torch.ops.aten.prod(self,dtype)|Tensor,ScalarType?
torch.ops.aten.prod.dim_int(self,dim,keepdim,dtype)|Tensor,int,bool,ScalarType?
torch.ops.aten.prod.dim_Dimname(self,dim,keepdim,dtype)|Tensor,str,bool,ScalarType?
torch.ops.aten.prod.Dimname_out(self,dim,keepdim,dtype,out)|Tensor,str,bool,ScalarType?,Tensor(a!)
torch.ops.aten.prod.int_out(self,dim,keepdim,dtype,out)|Tensor,int,bool,ScalarType?,Tensor(a!)
torch.ops.aten.prod.out(self,dtype,out)|Tensor,ScalarType?,Tensor(a!)
torch.ops.aten.quantized_gru.input(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first)|Tensor,Tensor,__torch__.torch.classes.rnn.CellParamsBase[],bool,int,float,bool,bool,bool
torch.ops.aten.quantized_gru.data(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional)|Tensor,Tensor,Tensor,__torch__.torch.classes.rnn.CellParamsBase[],bool,int,float,bool,bool
torch.ops.aten.quantized_gru.input_legacy(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first)|Tensor,Tensor,Tensor[],bool,int,float,bool,bool,bool
torch.ops.aten.quantized_gru.data_legacy(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional)|Tensor,Tensor,Tensor,Tensor[],bool,int,float,bool,bool
torch.ops.aten.quantized_lstm.input(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first,dtype,use_dynamic)|Tensor,Tensor[],__torch__.torch.classes.rnn.CellParamsBase[],bool,int,float,bool,bool,bool,ScalarType?,bool
torch.ops.aten.quantized_lstm.data(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional,dtype,use_dynamic)|Tensor,Tensor,Tensor[],__torch__.torch.classes.rnn.CellParamsBase[],bool,int,float,bool,bool,ScalarType?,bool
torch.ops.aten.quantized_lstm.input_legacy(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first,dtype,use_dynamic)|Tensor,Tensor[],Tensor[],bool,int,float,bool,bool,bool,ScalarType?,bool
torch.ops.aten.quantized_lstm.data_legacy(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional,dtype,use_dynamic)|Tensor,Tensor,Tensor[],Tensor[],bool,int,float,bool,bool,ScalarType?,bool
torch.ops.aten.rad2deg(self)|Tensor
torch.ops.aten.rad2deg.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.rad2deg_(self)|Tensor(a!)
torch.ops.aten.rand(size,dtype,layout,device,pin_memory)|SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.rand.generator(size,generator,dtype,layout,device,pin_memory)|SymInt[],Generator?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.rand.names(size,names,dtype,layout,device,pin_memory)|SymInt[],str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.rand.generator_with_names(size,generator,names,dtype,layout,device,pin_memory)|SymInt[],Generator?,str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.rand.out(size,out)|SymInt[],Tensor(a!)
torch.ops.aten.rand.generator_out(size,generator,out)|SymInt[],Generator?,Tensor(a!)
torch.ops.aten.rand.names_out(size,names,out)|SymInt[],str[]?,Tensor(a!)
torch.ops.aten.rand.generator_with_names_out(size,generator,names,out)|SymInt[],Generator?,str[]?,Tensor(a!)
torch.ops.aten.rand_like(self,dtype,layout,device,pin_memory,memory_format)|Tensor,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.rand_like.out(self,memory_format,out)|Tensor,MemoryFormat?,Tensor(a!)
torch.ops.aten.randint(high,size,dtype,layout,device,pin_memory)|SymInt,SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randint.generator(high,size,generator,dtype,layout,device,pin_memory)|SymInt,SymInt[],Generator?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randint.low(low,high,size,dtype,layout,device,pin_memory)|SymInt,SymInt,SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randint.low_generator(low,high,size,generator,dtype,layout,device,pin_memory)|SymInt,SymInt,SymInt[],Generator?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randint.out(high,size,out)|SymInt,SymInt[],Tensor(a!)
torch.ops.aten.randint.generator_out(high,size,generator,out)|SymInt,SymInt[],Generator?,Tensor(a!)
torch.ops.aten.randint.low_out(low,high,size,out)|SymInt,SymInt,SymInt[],Tensor(a!)
torch.ops.aten.randint.low_generator_out(low,high,size,generator,out)|SymInt,SymInt,SymInt[],Generator?,Tensor(a!)
torch.ops.aten.randint_like(self,high,dtype,layout,device,pin_memory,memory_format)|Tensor,SymInt,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.randint_like.low_dtype(self,low,high,dtype,layout,device,pin_memory,memory_format)|Tensor,SymInt,SymInt,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.randint_like.out(self,high,memory_format,out)|Tensor,SymInt,MemoryFormat?,Tensor(a!)
torch.ops.aten.randint_like.low_dtype_out(self,low,high,memory_format,out)|Tensor,SymInt,SymInt,MemoryFormat?,Tensor(a!)
torch.ops.aten.randn(size,dtype,layout,device,pin_memory)|SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randn.generator(size,generator,dtype,layout,device,pin_memory)|SymInt[],Generator?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randn.names(size,names,dtype,layout,device,pin_memory)|SymInt[],str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randn.generator_with_names(size,generator,names,dtype,layout,device,pin_memory)|SymInt[],Generator?,str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randn.out(size,out)|SymInt[],Tensor(a!)
torch.ops.aten.randn.generator_out(size,generator,out)|SymInt[],Generator?,Tensor(a!)
torch.ops.aten.randn.names_out(size,names,out)|SymInt[],str[]?,Tensor(a!)
torch.ops.aten.randn.generator_with_names_out(size,generator,names,out)|SymInt[],Generator?,str[]?,Tensor(a!)
torch.ops.aten.randn_like(self,dtype,layout,device,pin_memory,memory_format)|Tensor,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.randn_like.out(self,memory_format,out)|Tensor,MemoryFormat?,Tensor(a!)
torch.ops.aten.randperm(n,dtype,layout,device,pin_memory)|SymInt,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randperm.generator(n,generator,dtype,layout,device,pin_memory)|SymInt,Generator?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.randperm.out(n,out)|SymInt,Tensor(a!)
torch.ops.aten.randperm.generator_out(n,generator,out)|SymInt,Generator?,Tensor(a!)
torch.ops.aten.real(self)|Tensor(a)
torch.ops.aten.reciprocal(self)|Tensor
torch.ops.aten.reciprocal.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.reciprocal_(self)|Tensor(a!)
torch.ops.aten.reflection_pad1d(self,padding)|Tensor,SymInt[2]
torch.ops.aten.reflection_pad1d.out(self,padding,out)|Tensor,SymInt[2],Tensor(a!)
torch.ops.aten.reflection_pad1d_backward(grad_output,self,padding)|Tensor,Tensor,SymInt[2]
torch.ops.aten.reflection_pad1d_backward.grad_input(grad_output,self,padding,grad_input)|Tensor,Tensor,SymInt[2],Tensor(a!)
torch.ops.aten.reflection_pad2d(self,padding)|Tensor,SymInt[4]
torch.ops.aten.reflection_pad2d.out(self,padding,out)|Tensor,SymInt[4],Tensor(a!)
torch.ops.aten.reflection_pad2d_backward(grad_output,self,padding)|Tensor,Tensor,SymInt[4]
torch.ops.aten.reflection_pad2d_backward.grad_input(grad_output,self,padding,grad_input)|Tensor,Tensor,SymInt[4],Tensor(a!)
torch.ops.aten.reflection_pad3d(self,padding)|Tensor,SymInt[6]
torch.ops.aten.reflection_pad3d.out(self,padding,out)|Tensor,SymInt[6],Tensor(a!)
torch.ops.aten.reflection_pad3d_backward(grad_output,self,padding)|Tensor,Tensor,SymInt[6]
torch.ops.aten.reflection_pad3d_backward.grad_input(grad_output,self,padding,grad_input)|Tensor,Tensor,SymInt[6],Tensor(a!)
torch.ops.aten.relu(self)|Tensor
torch.ops.aten.relu.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.relu6(self)|Tensor
torch.ops.aten.relu_(self)|Tensor(a!)
torch.ops.aten.remainder.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.remainder.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.remainder.Scalar_Tensor(self,other)|Scalar,Tensor
torch.ops.aten.remainder.Tensor_out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.remainder.Scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.remainder.Scalar_Tensor_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.remainder.int(a,b)|int,int
torch.ops.aten.remainder.float(a,b)|float,float
torch.ops.aten.remainder.int_float(a,b)|int,float
torch.ops.aten.remainder.float_int(a,b)|float,int
torch.ops.aten.remainder(a,b)|Scalar,Scalar
torch.ops.aten.remainder_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.remainder_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.renorm(self,p,dim,maxnorm)|Tensor,Scalar,int,Scalar
torch.ops.aten.renorm.out(self,p,dim,maxnorm,out)|Tensor,Scalar,int,Scalar,Tensor(a!)
torch.ops.aten.renorm_(self,p,dim,maxnorm)|Tensor(a!),Scalar,int,Scalar
torch.ops.aten.repeat(self,repeats)|Tensor,SymInt[]
torch.ops.aten.repeat.out(self,repeats,out)|Tensor,SymInt[],Tensor(a!)
torch.ops.aten.repeat_interleave.Tensor(repeats,output_size)|Tensor,SymInt?
torch.ops.aten.repeat_interleave.self_Tensor(self,repeats,dim,output_size)|Tensor,Tensor,int?,SymInt?
torch.ops.aten.repeat_interleave.self_int(self,repeats,dim,output_size)|Tensor,SymInt,int?,SymInt?
torch.ops.aten.repeat_interleave.Tensor_out(repeats,output_size,out)|Tensor,SymInt?,Tensor(a!)
torch.ops.aten.replication_pad1d(self,padding)|Tensor,SymInt[2]
torch.ops.aten.replication_pad1d.out(self,padding,out)|Tensor,SymInt[2],Tensor(a!)
torch.ops.aten.replication_pad1d_backward(grad_output,self,padding)|Tensor,Tensor,SymInt[2]
torch.ops.aten.replication_pad1d_backward.grad_input(grad_output,self,padding,grad_input)|Tensor,Tensor,SymInt[2],Tensor(a!)
torch.ops.aten.replication_pad2d(self,padding)|Tensor,SymInt[4]
torch.ops.aten.replication_pad2d.out(self,padding,out)|Tensor,SymInt[4],Tensor(a!)
torch.ops.aten.replication_pad2d_backward(grad_output,self,padding)|Tensor,Tensor,SymInt[4]
torch.ops.aten.replication_pad2d_backward.grad_input(grad_output,self,padding,grad_input)|Tensor,Tensor,SymInt[4],Tensor(a!)
torch.ops.aten.replication_pad3d(self,padding)|Tensor,SymInt[6]
torch.ops.aten.replication_pad3d.out(self,padding,out)|Tensor,SymInt[6],Tensor(a!)
torch.ops.aten.replication_pad3d_backward(grad_output,self,padding)|Tensor,Tensor,SymInt[6]
torch.ops.aten.replication_pad3d_backward.grad_input(grad_output,self,padding,grad_input)|Tensor,Tensor,SymInt[6],Tensor(a!)
torch.ops.aten.reshape(self,shape)|Tensor(a),SymInt[]
torch.ops.aten.resize(self,size,memory_format)|Tensor,SymInt[],MemoryFormat?
torch.ops.aten.resize.out(self,size,memory_format,out)|Tensor,SymInt[],MemoryFormat?,Tensor(a!)
torch.ops.aten.resize_as(self,the_template,memory_format)|Tensor,Tensor,MemoryFormat?
torch.ops.aten.resize_as.out(self,the_template,memory_format,out)|Tensor,Tensor,MemoryFormat?,Tensor(a!)
torch.ops.aten.resize_as_(self,the_template,memory_format)|Tensor(a!),Tensor,MemoryFormat?
torch.ops.aten.rnn_relu.input(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first)|Tensor,Tensor,Tensor[],bool,int,float,bool,bool,bool
torch.ops.aten.rnn_relu.data(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional)|Tensor,Tensor,Tensor,Tensor[],bool,int,float,bool,bool
torch.ops.aten.rnn_tanh.input(input,hx,params,has_biases,num_layers,dropout,train,bidirectional,batch_first)|Tensor,Tensor,Tensor[],bool,int,float,bool,bool,bool
torch.ops.aten.rnn_tanh.data(data,batch_sizes,hx,params,has_biases,num_layers,dropout,train,bidirectional)|Tensor,Tensor,Tensor,Tensor[],bool,int,float,bool,bool
torch.ops.aten.roll(self,shifts,dims)|Tensor,SymInt[1],int[1]
torch.ops.aten.roll.out(self,shifts,dims,out)|Tensor,SymInt[1],int[1],Tensor(a!)
torch.ops.aten.rot90(self,k,dims)|Tensor,int,int[]
torch.ops.aten.rot90.out(self,k,dims,out)|Tensor,int,int[],Tensor(a!)
torch.ops.aten.round(self)|Tensor
torch.ops.aten.round.decimals(self,decimals)|Tensor,int
torch.ops.aten.round.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.round.decimals_out(self,decimals,out)|Tensor,int,Tensor(a!)
torch.ops.aten.round.int(a)|int
torch.ops.aten.round.float(a)|float
torch.ops.aten.round.Scalar(a)|Scalar
torch.ops.aten.round_(self)|Tensor(a!)
torch.ops.aten.round_.decimals(self,decimals)|Tensor(a!),int
torch.ops.aten.rrelu_with_noise(self,noise,lower,upper,training,generator)|Tensor,Tensor,Scalar,Scalar,bool,Generator?
torch.ops.aten.rrelu_with_noise.out(self,noise,lower,upper,training,generator,out)|Tensor,Tensor,Scalar,Scalar,bool,Generator?,Tensor(a!)
torch.ops.aten.rrelu_with_noise_(self,noise,lower,upper,training,generator)|Tensor(a!),Tensor,Scalar,Scalar,bool,Generator?
torch.ops.aten.rrelu_with_noise_backward(grad_output,self,noise,lower,upper,training,self_is_result)|Tensor,Tensor,Tensor,Scalar,Scalar,bool,bool
torch.ops.aten.rrelu_with_noise_backward.out(grad_output,self,noise,lower,upper,training,self_is_result,out)|Tensor,Tensor,Tensor,Scalar,Scalar,bool,bool,Tensor(a!)
torch.ops.aten.rsqrt(self)|Tensor
torch.ops.aten.rsqrt.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.rsqrt_(self)|Tensor(a!)
torch.ops.aten.rsub.Tensor(self,other,alpha)|Tensor,Tensor,Scalar
torch.ops.aten.rsub.Scalar(self,other,alpha)|Tensor,Scalar,Scalar
torch.ops.aten.rsub.Tensor_out(self,other,alpha,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.rsub.Scalar_out(self,other,alpha,out)|Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.scalar_tensor(s,dtype,layout,device,pin_memory)|Scalar,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.scalar_tensor.out(s,out)|Scalar,Tensor(a!)
torch.ops.aten.scatter.value(self,dim,index,value)|Tensor,int,Tensor,Scalar
torch.ops.aten.scatter.src(self,dim,index,src)|Tensor,int,Tensor,Tensor
torch.ops.aten.scatter.reduce(self,dim,index,src,reduce)|Tensor,int,Tensor,Tensor,str
torch.ops.aten.scatter.value_reduce(self,dim,index,value,reduce)|Tensor,int,Tensor,Scalar,str
torch.ops.aten.scatter.src_out(self,dim,index,src,out)|Tensor,int,Tensor,Tensor,Tensor(a!)
torch.ops.aten.scatter.value_out(self,dim,index,value,out)|Tensor,int,Tensor,Scalar,Tensor(a!)
torch.ops.aten.scatter.reduce_out(self,dim,index,src,reduce,out)|Tensor,int,Tensor,Tensor,str,Tensor(a!)
torch.ops.aten.scatter.value_reduce_out(self,dim,index,value,reduce,out)|Tensor,int,Tensor,Scalar,str,Tensor(a!)
torch.ops.aten.scatter.dimname_src(self,dim,index,src)|Tensor,str,Tensor,Tensor
torch.ops.aten.scatter.dimname_value(self,dim,index,value)|Tensor,str,Tensor,Scalar
torch.ops.aten.scatter_.src(self,dim,index,src)|Tensor(a!),int,Tensor,Tensor
torch.ops.aten.scatter_.value(self,dim,index,value)|Tensor(a!),int,Tensor,Scalar
torch.ops.aten.scatter_.reduce(self,dim,index,src,reduce)|Tensor(a!),int,Tensor,Tensor,str
torch.ops.aten.scatter_.value_reduce(self,dim,index,value,reduce)|Tensor(a!),int,Tensor,Scalar,str
torch.ops.aten.scatter_add(self,dim,index,src)|Tensor,int,Tensor,Tensor
torch.ops.aten.scatter_add.out(self,dim,index,src,out)|Tensor,int,Tensor,Tensor,Tensor(a!)
torch.ops.aten.scatter_add.dimname(self,dim,index,src)|Tensor,str,Tensor,Tensor
torch.ops.aten.scatter_add_(self,dim,index,src)|Tensor(a!),int,Tensor,Tensor
torch.ops.aten.scatter_reduce.two(self,dim,index,src,reduce,include_self)|Tensor,int,Tensor,Tensor,str,bool
torch.ops.aten.scatter_reduce.two_out(self,dim,index,src,reduce,include_self,out)|Tensor,int,Tensor,Tensor,str,bool,Tensor(a!)
torch.ops.aten.scatter_reduce_.two(self,dim,index,src,reduce,include_self)|Tensor(a!),int,Tensor,Tensor,str,bool
torch.ops.aten.searchsorted.Tensor(sorted_sequence,self,out_int32,right,side,sorter)|Tensor,Tensor,bool,bool,str?,Tensor?
torch.ops.aten.searchsorted.Tensor_out(sorted_sequence,self,out_int32,right,side,sorter,out)|Tensor,Tensor,bool,bool,str?,Tensor?,Tensor(a!)
torch.ops.aten.searchsorted.Scalar(sorted_sequence,self,out_int32,right,side,sorter)|Tensor,Scalar,bool,bool,str?,Tensor?
torch.ops.aten.searchsorted.Scalar_out(sorted_sequence,self,out_int32,right,side,sorter,out)|Tensor,Scalar,bool,bool,str?,Tensor?,Tensor(a!)
torch.ops.aten.segment_reduce(data,reduce,lengths,indices,offsets,axis,unsafe,initial)|Tensor,str,Tensor?,Tensor?,Tensor?,int,bool,Scalar?
torch.ops.aten.segment_reduce.out(data,reduce,lengths,indices,offsets,axis,unsafe,initial,out)|Tensor,str,Tensor?,Tensor?,Tensor?,int,bool,Scalar?,Tensor(a!)
torch.ops.aten.select.Dimname(self,dim,index)|Tensor(a),str,int
torch.ops.aten.select.int(self,dim,index)|Tensor(a),int,SymInt
torch.ops.aten.select.t(list,idx)|t[](a),int
torch.ops.aten.select_backward(grad_output,input_sizes,dim,index)|Tensor,SymInt[],int,SymInt
torch.ops.aten.select_backward.out(grad_output,input_sizes,dim,index,out)|Tensor,SymInt[],int,SymInt,Tensor(a!)
torch.ops.aten.select_scatter(self,src,dim,index)|Tensor,Tensor,int,SymInt
torch.ops.aten.select_scatter.out(self,src,dim,index,out)|Tensor,Tensor,int,SymInt,Tensor(a!)
torch.ops.aten.selu(self)|Tensor
torch.ops.aten.selu_(self)|Tensor(a!)
torch.ops.aten.set_.source_Storage_storage_offset(self,source,storage_offset,size,stride)|Tensor(a!),Storage,SymInt,SymInt[],SymInt[]
torch.ops.aten.set_.source_Tensor(self,source)|Tensor(a!),Tensor
torch.ops.aten.set_(self)|Tensor(a!)
torch.ops.aten.set_.source_Storage(self,source)|Tensor(a!),Storage
torch.ops.aten.set_.source_Tensor_storage_offset(self,source,storage_offset,size,stride)|Tensor(a!),Tensor,SymInt,SymInt[],SymInt[]
torch.ops.aten.sgn(self)|Tensor
torch.ops.aten.sgn.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sgn_(self)|Tensor(a!)
torch.ops.aten.sigmoid(self)|Tensor
torch.ops.aten.sigmoid.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sigmoid_(self)|Tensor(a!)
torch.ops.aten.sigmoid_backward(grad_output,output)|Tensor,Tensor
torch.ops.aten.sigmoid_backward.grad_input(grad_output,output,grad_input)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.sign(self)|Tensor
torch.ops.aten.sign.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sign_(self)|Tensor(a!)
torch.ops.aten.signbit(self)|Tensor
torch.ops.aten.signbit.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.silu(self)|Tensor
torch.ops.aten.silu.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.silu_(self)|Tensor(a!)
torch.ops.aten.silu_backward(grad_output,self)|Tensor,Tensor
torch.ops.aten.silu_backward.grad_input(grad_output,self,grad_input)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.sin(self)|Tensor
torch.ops.aten.sin.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sin.int(a)|int
torch.ops.aten.sin.float(a)|float
torch.ops.aten.sin.complex(a)|complex
torch.ops.aten.sin.Scalar(a)|Scalar
torch.ops.aten.sin_(self)|Tensor(a!)
torch.ops.aten.sinc(self)|Tensor
torch.ops.aten.sinc.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sinc_(self)|Tensor(a!)
torch.ops.aten.sinh(self)|Tensor
torch.ops.aten.sinh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sinh.int(a)|int
torch.ops.aten.sinh.float(a)|float
torch.ops.aten.sinh.complex(a)|complex
torch.ops.aten.sinh.Scalar(a)|Scalar
torch.ops.aten.sinh_(self)|Tensor(a!)
torch.ops.aten.size.int(self,dim)|Tensor,int
torch.ops.aten.size.Dimname(self,dim)|Tensor,str
torch.ops.aten.size(self)|Tensor
torch.ops.aten.slice.Tensor(self,dim,start,end,step)|Tensor(a),int,SymInt?,SymInt?,SymInt
torch.ops.aten.slice.t(l,start,end,step)|t[],int?,int?,int
torch.ops.aten.slice.str(string,start,end,step)|str,int?,int?,int
torch.ops.aten.slice_backward(grad_output,input_sizes,dim,start,end,step)|Tensor,SymInt[],int,SymInt,SymInt,SymInt
torch.ops.aten.slice_backward.out(grad_output,input_sizes,dim,start,end,step,out)|Tensor,SymInt[],int,SymInt,SymInt,SymInt,Tensor(a!)
torch.ops.aten.slice_scatter(self,src,dim,start,end,step)|Tensor,Tensor,int,SymInt?,SymInt?,SymInt
torch.ops.aten.slice_scatter.out(self,src,dim,start,end,step,out)|Tensor,Tensor,int,SymInt?,SymInt?,SymInt,Tensor(a!)
torch.ops.aten.smooth_l1_loss(self,target,reduction,beta)|Tensor,Tensor,int,float
torch.ops.aten.smooth_l1_loss.out(self,target,reduction,beta,out)|Tensor,Tensor,int,float,Tensor(a!)
torch.ops.aten.smooth_l1_loss_backward.grad_input(grad_output,self,target,reduction,beta,grad_input)|Tensor,Tensor,Tensor,int,float,Tensor(a!)
torch.ops.aten.smooth_l1_loss_backward(grad_output,self,target,reduction,beta)|Tensor,Tensor,Tensor,int,float
torch.ops.aten.soft_margin_loss(self,target,reduction)|Tensor,Tensor,int
torch.ops.aten.soft_margin_loss.out(self,target,reduction,out)|Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.soft_margin_loss_backward(grad_output,self,target,reduction)|Tensor,Tensor,Tensor,int
torch.ops.aten.soft_margin_loss_backward.grad_input(grad_output,self,target,reduction,grad_input)|Tensor,Tensor,Tensor,int,Tensor(a!)
torch.ops.aten.softplus(self,beta,threshold)|Tensor,Scalar,Scalar
torch.ops.aten.softplus.out(self,beta,threshold,out)|Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.softplus_backward(grad_output,self,beta,threshold)|Tensor,Tensor,Scalar,Scalar
torch.ops.aten.softplus_backward.grad_input(grad_output,self,beta,threshold,grad_input)|Tensor,Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.softshrink(self,lambd)|Tensor,Scalar
torch.ops.aten.softshrink.out(self,lambd,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.sort(self,dim,descending)|Tensor,int,bool
torch.ops.aten.sort.stable(self,stable,dim,descending)|Tensor,bool?,int,bool
torch.ops.aten.sort.values_stable(self,stable,dim,descending,values,indices)|Tensor,bool?,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.sort.values(self,dim,descending,values,indices)|Tensor,int,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.sort.dimname(self,dim,descending)|Tensor,str,bool
torch.ops.aten.sort.dimname_values(self,dim,descending,values,indices)|Tensor,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.sort.dimname_stable(self,stable,dim,descending)|Tensor,bool?,str,bool
torch.ops.aten.sort.dimname_values_stable(self,stable,dim,descending,values,indices)|Tensor,bool?,str,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.sort.int(self,reverse)|int[](a!),bool
torch.ops.aten.sort.float(self,reverse)|float[](a!),bool
torch.ops.aten.sort.Tensor(self,reverse)|Tensor[](a!),bool
torch.ops.aten.sort.bool(self,reverse)|bool[](a!),bool
torch.ops.aten.sort.str(self,reverse)|str[](a!),bool
torch.ops.aten.sort.any(self,reverse)|t[](a!),bool
torch.ops.aten.sparse_dim(self)|Tensor
torch.ops.aten.special_airy_ai(x)|Tensor
torch.ops.aten.special_airy_ai.out(x,out)|Tensor,Tensor(a!)
torch.ops.aten.special_bessel_j0(self)|Tensor
torch.ops.aten.special_bessel_j0.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_bessel_j1(self)|Tensor
torch.ops.aten.special_bessel_j1.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_bessel_y0(self)|Tensor
torch.ops.aten.special_bessel_y0.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_bessel_y1(self)|Tensor
torch.ops.aten.special_bessel_y1.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_t(x,n)|Tensor,Tensor
torch.ops.aten.special_chebyshev_polynomial_t.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_t.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_chebyshev_polynomial_t.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_t.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_chebyshev_polynomial_t.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_u(x,n)|Tensor,Tensor
torch.ops.aten.special_chebyshev_polynomial_u.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_u.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_chebyshev_polynomial_u.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_u.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_chebyshev_polynomial_u.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_v(x,n)|Tensor,Tensor
torch.ops.aten.special_chebyshev_polynomial_v.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_v.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_chebyshev_polynomial_v.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_v.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_chebyshev_polynomial_v.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_w(x,n)|Tensor,Tensor
torch.ops.aten.special_chebyshev_polynomial_w.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_w.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_chebyshev_polynomial_w.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_chebyshev_polynomial_w.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_chebyshev_polynomial_w.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_entr(self)|Tensor
torch.ops.aten.special_entr.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_erfcx(self)|Tensor
torch.ops.aten.special_erfcx.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_hermite_polynomial_h(x,n)|Tensor,Tensor
torch.ops.aten.special_hermite_polynomial_h.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_hermite_polynomial_h.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_hermite_polynomial_h.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_hermite_polynomial_h.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_hermite_polynomial_h.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_hermite_polynomial_he(x,n)|Tensor,Tensor
torch.ops.aten.special_hermite_polynomial_he.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_hermite_polynomial_he.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_hermite_polynomial_he.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_hermite_polynomial_he.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_hermite_polynomial_he.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_i0e(self)|Tensor
torch.ops.aten.special_i0e.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_i1(self)|Tensor
torch.ops.aten.special_i1.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_i1e(self)|Tensor
torch.ops.aten.special_i1e.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_laguerre_polynomial_l(x,n)|Tensor,Tensor
torch.ops.aten.special_laguerre_polynomial_l.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_laguerre_polynomial_l.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_laguerre_polynomial_l.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_laguerre_polynomial_l.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_laguerre_polynomial_l.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_legendre_polynomial_p(x,n)|Tensor,Tensor
torch.ops.aten.special_legendre_polynomial_p.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_legendre_polynomial_p.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_legendre_polynomial_p.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_legendre_polynomial_p.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_legendre_polynomial_p.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_log_ndtr(self)|Tensor
torch.ops.aten.special_log_ndtr.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_modified_bessel_i0(self)|Tensor
torch.ops.aten.special_modified_bessel_i0.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_modified_bessel_i1(self)|Tensor
torch.ops.aten.special_modified_bessel_i1.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_modified_bessel_k0(self)|Tensor
torch.ops.aten.special_modified_bessel_k0.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_modified_bessel_k1(self)|Tensor
torch.ops.aten.special_modified_bessel_k1.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_ndtr(self)|Tensor
torch.ops.aten.special_ndtr.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_ndtri(self)|Tensor
torch.ops.aten.special_ndtri.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.special_scaled_modified_bessel_k0(x)|Tensor
torch.ops.aten.special_scaled_modified_bessel_k0.out(x,out)|Tensor,Tensor(a!)
torch.ops.aten.special_scaled_modified_bessel_k1(x)|Tensor
torch.ops.aten.special_scaled_modified_bessel_k1.out(x,out)|Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_t(x,n)|Tensor,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_t.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_t.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_t.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_t.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_shifted_chebyshev_polynomial_t.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_u(x,n)|Tensor,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_u.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_u.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_u.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_u.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_shifted_chebyshev_polynomial_u.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_v(x,n)|Tensor,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_v.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_v.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_v.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_v.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_shifted_chebyshev_polynomial_v.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_w(x,n)|Tensor,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_w.out(x,n,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_w.x_scalar(x,n)|Scalar,Tensor
torch.ops.aten.special_shifted_chebyshev_polynomial_w.x_scalar_out(x,n,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_shifted_chebyshev_polynomial_w.n_scalar(x,n)|Tensor,Scalar
torch.ops.aten.special_shifted_chebyshev_polynomial_w.n_scalar_out(x,n,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_spherical_bessel_j0(x)|Tensor
torch.ops.aten.special_spherical_bessel_j0.out(x,out)|Tensor,Tensor(a!)
torch.ops.aten.special_xlog1py(self,other)|Tensor,Tensor
torch.ops.aten.special_xlog1py.other_scalar(self,other)|Tensor,Scalar
torch.ops.aten.special_xlog1py.self_scalar(self,other)|Scalar,Tensor
torch.ops.aten.special_xlog1py.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_xlog1py.self_scalar_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_xlog1py.other_scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.special_zeta(self,other)|Tensor,Tensor
torch.ops.aten.special_zeta.other_scalar(self,other)|Tensor,Scalar
torch.ops.aten.special_zeta.self_scalar(self,other)|Scalar,Tensor
torch.ops.aten.special_zeta.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.special_zeta.self_scalar_out(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.special_zeta.other_scalar_out(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.split.str(self,separator,max)|str,str?,int
torch.ops.aten.split_with_sizes_copy(self,split_sizes,dim)|Tensor,SymInt[],int
torch.ops.aten.split_with_sizes_copy.out(self,split_sizes,dim,out)|Tensor,SymInt[],int,Tensor(a!)[]
torch.ops.aten.sqrt(self)|Tensor
torch.ops.aten.sqrt.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.sqrt.int(a)|int
torch.ops.aten.sqrt.float(a)|float
torch.ops.aten.sqrt.complex(a)|complex
torch.ops.aten.sqrt.Scalar(a)|Scalar
torch.ops.aten.sqrt_(self)|Tensor(a!)
torch.ops.aten.square(self)|Tensor
torch.ops.aten.square.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.square_(self)|Tensor(a!)
torch.ops.aten.squeeze(self)|Tensor(a)
torch.ops.aten.squeeze.dim(self,dim)|Tensor(a),int
torch.ops.aten.squeeze.dims(self,dim)|Tensor(a),int[]
torch.ops.aten.squeeze.dimname(self,dim)|Tensor(a),str
torch.ops.aten.stack(tensors,dim)|Tensor[],int
torch.ops.aten.stack.out(tensors,dim,out)|Tensor[],int,Tensor(a!)
torch.ops.aten.std(self,unbiased)|Tensor,bool
torch.ops.aten.std.dim(self,dim,unbiased,keepdim)|Tensor,int[1]?,bool,bool
torch.ops.aten.std.correction(self,dim,correction,keepdim)|Tensor,int[1]?,Scalar?,bool
torch.ops.aten.std.names_dim(self,dim,unbiased,keepdim)|Tensor,str[1],bool,bool
torch.ops.aten.std.names_out(self,dim,unbiased,keepdim,out)|Tensor,str[1],bool,bool,Tensor(a!)
torch.ops.aten.std.out(self,dim,unbiased,keepdim,out)|Tensor,int[1]?,bool,bool,Tensor(a!)
torch.ops.aten.std.correction_out(self,dim,correction,keepdim,out)|Tensor,int[1]?,Scalar?,bool,Tensor(a!)
torch.ops.aten.std.correction_names(self,dim,correction,keepdim)|Tensor,str[1],Scalar?,bool
torch.ops.aten.std.correction_names_out(self,dim,correction,keepdim,out)|Tensor,str[1],Scalar?,bool,Tensor(a!)
torch.ops.aten.std_mean(self,unbiased)|Tensor,bool
torch.ops.aten.std_mean.dim(self,dim,unbiased,keepdim)|Tensor,int[1]?,bool,bool
torch.ops.aten.std_mean.correction(self,dim,correction,keepdim)|Tensor,int[1]?,Scalar?,bool
torch.ops.aten.std_mean.names_dim(self,dim,unbiased,keepdim)|Tensor,str[1],bool,bool
torch.ops.aten.std_mean.correction_names(self,dim,correction,keepdim)|Tensor,str[1],Scalar?,bool
torch.ops.aten.std_mean.correction_out(self,dim,correction,keepdim,out0,out1)|Tensor,int[1]?,Scalar?,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.stft(self,n_fft,hop_length,win_length,window,normalized,onesided,return_complex)|Tensor,int,int?,int?,Tensor?,bool,bool?,bool?
torch.ops.aten.stft.center(self,n_fft,hop_length,win_length,window,center,pad_mode,normalized,onesided,return_complex)|Tensor,int,int?,int?,Tensor?,bool,str,bool,bool?,bool?
torch.ops.aten.storage_offset(self)|Tensor
torch.ops.aten.stride.int(self,dim)|Tensor,int
torch.ops.aten.stride.Dimname(self,dim)|Tensor,str
torch.ops.aten.stride(self)|Tensor
torch.ops.aten.sub.Tensor(self,other,alpha)|Tensor,Tensor,Scalar
torch.ops.aten.sub.Scalar(self,other,alpha)|Tensor,Scalar,Scalar
torch.ops.aten.sub.out(self,other,alpha,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.sub.Scalar_out(self,other,alpha,out)|Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.sub.int(a,b)|int,int
torch.ops.aten.sub.complex(a,b)|complex,complex
torch.ops.aten.sub.float(a,b)|float,float
torch.ops.aten.sub.int_complex(a,b)|int,complex
torch.ops.aten.sub.complex_int(a,b)|complex,int
torch.ops.aten.sub.float_complex(a,b)|float,complex
torch.ops.aten.sub.complex_float(a,b)|complex,float
torch.ops.aten.sub.int_float(a,b)|int,float
torch.ops.aten.sub.float_int(a,b)|float,int
torch.ops.aten.sub(a,b)|Scalar,Scalar
torch.ops.aten.sub_.Tensor(self,other,alpha)|Tensor(a!),Tensor,Scalar
torch.ops.aten.sub_.Scalar(self,other,alpha)|Tensor(a!),Scalar,Scalar
torch.ops.aten.subtract.Tensor(self,other,alpha)|Tensor,Tensor,Scalar
torch.ops.aten.subtract.out(self,other,alpha,out)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.subtract.Scalar(self,other,alpha)|Tensor,Scalar,Scalar
torch.ops.aten.subtract_.Tensor(self,other,alpha)|Tensor(a!),Tensor,Scalar
torch.ops.aten.subtract_.Scalar(self,other,alpha)|Tensor(a!),Scalar,Scalar
torch.ops.aten.sum.dim_IntList(self,dim,keepdim,dtype)|Tensor,int[1]?,bool,ScalarType?
torch.ops.aten.sum(self,dtype)|Tensor,ScalarType?
torch.ops.aten.sum.dim_DimnameList(self,dim,keepdim,dtype)|Tensor,str[1],bool,ScalarType?
torch.ops.aten.sum.DimnameList_out(self,dim,keepdim,dtype,out)|Tensor,str[1],bool,ScalarType?,Tensor(a!)
torch.ops.aten.sum.IntList_out(self,dim,keepdim,dtype,out)|Tensor,int[1]?,bool,ScalarType?,Tensor(a!)
torch.ops.aten.sum.out(self,dtype,out)|Tensor,ScalarType?,Tensor(a!)
torch.ops.aten.sum.int(self)|int[]
torch.ops.aten.sum.float(self)|float[]
torch.ops.aten.sum.complex(self)|complex[]
torch.ops.aten.sum.bool(self)|bool[]
torch.ops.aten.svd(self,some,compute_uv)|Tensor,bool,bool
torch.ops.aten.svd.U(self,some,compute_uv,U,S,V)|Tensor,bool,bool,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.sym_constrain_range(size,min,max)|Scalar,int?,int?
torch.ops.aten.sym_constrain_range_for_size(size,min,max)|Scalar,int?,int?
torch.ops.aten.sym_numel(self)|Tensor
torch.ops.aten.sym_size.int(self,dim)|Tensor,int
torch.ops.aten.sym_size(self)|Tensor
torch.ops.aten.sym_storage_offset(self)|Tensor
torch.ops.aten.sym_stride.int(self,dim)|Tensor,int
torch.ops.aten.sym_stride(self)|Tensor
torch.ops.aten.t(self)|Tensor(a)
torch.ops.aten.t_(self)|Tensor(a!)
torch.ops.aten.t_copy.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.t_copy(self)|Tensor
torch.ops.aten.take(self,index)|Tensor,Tensor
torch.ops.aten.take.out(self,index,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.tan(self)|Tensor
torch.ops.aten.tan.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.tan.int(a)|int
torch.ops.aten.tan.float(a)|float
torch.ops.aten.tan.complex(a)|complex
torch.ops.aten.tan.Scalar(a)|Scalar
torch.ops.aten.tan_(self)|Tensor(a!)
torch.ops.aten.tanh(self)|Tensor
torch.ops.aten.tanh.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.tanh.int(a)|int
torch.ops.aten.tanh.float(a)|float
torch.ops.aten.tanh.complex(a)|complex
torch.ops.aten.tanh.Scalar(a)|Scalar
torch.ops.aten.tanh_(self)|Tensor(a!)
torch.ops.aten.tanh_backward(grad_output,output)|Tensor,Tensor
torch.ops.aten.tanh_backward.grad_input(grad_output,output,grad_input)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.threshold(self,threshold,value)|Tensor,Scalar,Scalar
torch.ops.aten.threshold.out(self,threshold,value,out)|Tensor,Scalar,Scalar,Tensor(a!)
torch.ops.aten.threshold_(self,threshold,value)|Tensor(a!),Scalar,Scalar
torch.ops.aten.threshold_backward(grad_output,self,threshold)|Tensor,Tensor,Scalar
torch.ops.aten.threshold_backward.grad_input(grad_output,self,threshold,grad_input)|Tensor,Tensor,Scalar,Tensor(a!)
torch.ops.aten.to.device(self,device,dtype,non_blocking,copy,memory_format)|Tensor(a),Device,ScalarType,bool,bool,MemoryFormat?
torch.ops.aten.to.dtype(self,dtype,non_blocking,copy,memory_format)|Tensor(a),ScalarType,bool,bool,MemoryFormat?
torch.ops.aten.to.other(self,other,non_blocking,copy,memory_format)|Tensor(a),Tensor,bool,bool,MemoryFormat?
torch.ops.aten.to.dtype_layout(self,dtype,layout,device,pin_memory,non_blocking,copy,memory_format)|Tensor(a),ScalarType?,Layout?,Device?,bool?,bool,bool,MemoryFormat?
torch.ops.aten.to.prim_Device(self,device,dtype,non_blocking,copy)|Tensor(a),Device?,int?,bool,bool
torch.ops.aten.to.prim_dtype(self,dtype,non_blocking,copy)|Tensor(a),int?,bool,bool
torch.ops.aten.to.prim_other(self,non_blocking,copy)|Tensor(a),bool,bool
torch.ops.aten.topk(self,k,dim,largest,sorted)|Tensor,SymInt,int,bool,bool
torch.ops.aten.topk.values(self,k,dim,largest,sorted,values,indices)|Tensor,SymInt,int,bool,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.trace(self)|Tensor
torch.ops.aten.trace.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.transpose.int(self,dim0,dim1)|Tensor(a),int,int
torch.ops.aten.transpose.Dimname(self,dim0,dim1)|Tensor(a),str,str
torch.ops.aten.transpose_(self,dim0,dim1)|Tensor(a!),int,int
torch.ops.aten.triangular_solve(self,A,upper,transpose,unitriangular)|Tensor,Tensor,bool,bool,bool
torch.ops.aten.triangular_solve.X(self,A,upper,transpose,unitriangular,X,M)|Tensor,Tensor,bool,bool,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.tril(self,diagonal)|Tensor,int
torch.ops.aten.tril.out(self,diagonal,out)|Tensor,int,Tensor(a!)
torch.ops.aten.tril_(self,diagonal)|Tensor(a!),int
torch.ops.aten.tril_indices(row,col,offset,dtype,layout,device,pin_memory)|int,int,int,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.tril_indices.out(row,col,offset,out)|int,int,int,Tensor(a!)
torch.ops.aten.triu(self,diagonal)|Tensor,int
torch.ops.aten.triu.out(self,diagonal,out)|Tensor,int,Tensor(a!)
torch.ops.aten.triu_(self,diagonal)|Tensor(a!),int
torch.ops.aten.triu_indices(row,col,offset,dtype,layout,device,pin_memory)|int,int,int,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.triu_indices.out(row,col,offset,out)|int,int,int,Tensor(a!)
torch.ops.aten.true_divide.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.true_divide.Scalar(self,other)|Tensor,Scalar
torch.ops.aten.true_divide.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.true_divide_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.true_divide_.Scalar(self,other)|Tensor(a!),Scalar
torch.ops.aten.trunc(self)|Tensor
torch.ops.aten.trunc.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.trunc_(self)|Tensor(a!)
torch.ops.aten.unfold(self,dimension,size,step)|Tensor(a),int,int,int
torch.ops.aten.unfold_backward(grad_in,input_sizes,dim,size,step)|Tensor,SymInt[],int,int,int
torch.ops.aten.unfold_backward.out(grad_in,input_sizes,dim,size,step,out)|Tensor,SymInt[],int,int,int,Tensor(a!)
torch.ops.aten.unfold_copy(self,dimension,size,step)|Tensor,int,int,int
torch.ops.aten.unfold_copy.out(self,dimension,size,step,out)|Tensor,int,int,int,Tensor(a!)
torch.ops.aten.uniform(self,from,to,generator)|Tensor,float,float,Generator?
torch.ops.aten.uniform.out(self,from,to,generator,out)|Tensor,float,float,Generator?,Tensor(a!)
torch.ops.aten.uniform_(self,from,to,generator)|Tensor(a!),float,float,Generator?
torch.ops.aten.unique_dim(self,dim,sorted,return_inverse,return_counts)|Tensor,int,bool,bool,bool
torch.ops.aten.unique_dim.out(self,dim,sorted,return_inverse,return_counts,out0,out1,out2)|Tensor,int,bool,bool,bool,Tensor(a!),Tensor(b!),Tensor(c!)
torch.ops.aten.unsafe_chunk(self,chunks,dim)|Tensor,int,int
torch.ops.aten.unsafe_split.Tensor(self,split_size,dim)|Tensor,SymInt,int
torch.ops.aten.unsafe_split.Tensor_out(self,split_size,dim,out)|Tensor,SymInt,int,Tensor(a!)[]
torch.ops.aten.unsafe_split_with_sizes(self,split_sizes,dim)|Tensor,SymInt[],int
torch.ops.aten.unsafe_split_with_sizes.out(self,split_sizes,dim,out)|Tensor,SymInt[],int,Tensor(a!)[]
torch.ops.aten.unsqueeze(self,dim)|Tensor(a),int
torch.ops.aten.unsqueeze_(self,dim)|Tensor(a!),int
torch.ops.aten.unsqueeze_copy.out(self,dim,out)|Tensor,int,Tensor(a!)
torch.ops.aten.unsqueeze_copy(self,dim)|Tensor,int
torch.ops.aten.upsample_bicubic2d(self,output_size,align_corners,scales_h,scales_w)|Tensor,SymInt[2],bool,float?,float?
torch.ops.aten.upsample_bicubic2d.vec(input,output_size,align_corners,scale_factors)|Tensor,SymInt[]?,bool,float[]?
torch.ops.aten.upsample_bicubic2d.out(self,output_size,align_corners,scales_h,scales_w,out)|Tensor,SymInt[2],bool,float?,float?,Tensor(a!)
torch.ops.aten.upsample_bilinear2d(self,output_size,align_corners,scales_h,scales_w)|Tensor,SymInt[2],bool,float?,float?
torch.ops.aten.upsample_bilinear2d.vec(input,output_size,align_corners,scale_factors)|Tensor,SymInt[]?,bool,float[]?
torch.ops.aten.upsample_bilinear2d.out(self,output_size,align_corners,scales_h,scales_w,out)|Tensor,SymInt[2],bool,float?,float?,Tensor(a!)
torch.ops.aten.upsample_linear1d(self,output_size,align_corners,scales)|Tensor,SymInt[1],bool,float?
torch.ops.aten.upsample_linear1d.vec(input,output_size,align_corners,scale_factors)|Tensor,SymInt[]?,bool,float[]?
torch.ops.aten.upsample_linear1d.out(self,output_size,align_corners,scales,out)|Tensor,SymInt[1],bool,float?,Tensor(a!)
torch.ops.aten.upsample_nearest1d(self,output_size,scales)|Tensor,SymInt[1],float?
torch.ops.aten.upsample_nearest1d.vec(input,output_size,scale_factors)|Tensor,SymInt[]?,float[]?
torch.ops.aten.upsample_nearest1d.out(self,output_size,scales,out)|Tensor,SymInt[1],float?,Tensor(a!)
torch.ops.aten.upsample_nearest2d(self,output_size,scales_h,scales_w)|Tensor,SymInt[2],float?,float?
torch.ops.aten.upsample_nearest2d.vec(input,output_size,scale_factors)|Tensor,SymInt[]?,float[]?
torch.ops.aten.upsample_nearest2d.out(self,output_size,scales_h,scales_w,out)|Tensor,SymInt[2],float?,float?,Tensor(a!)
torch.ops.aten.upsample_nearest2d_backward(grad_output,output_size,input_size,scales_h,scales_w)|Tensor,SymInt[2],SymInt[4],float?,float?
torch.ops.aten.upsample_nearest2d_backward.grad_input(grad_output,output_size,input_size,scales_h,scales_w,grad_input)|Tensor,SymInt[2],SymInt[4],float?,float?,Tensor(a!)
torch.ops.aten.upsample_nearest3d(self,output_size,scales_d,scales_h,scales_w)|Tensor,SymInt[3],float?,float?,float?
torch.ops.aten.upsample_nearest3d.vec(input,output_size,scale_factors)|Tensor,SymInt[]?,float[]?
torch.ops.aten.upsample_nearest3d.out(self,output_size,scales_d,scales_h,scales_w,out)|Tensor,SymInt[3],float?,float?,float?,Tensor(a!)
torch.ops.aten.upsample_trilinear3d(self,output_size,align_corners,scales_d,scales_h,scales_w)|Tensor,SymInt[3],bool,float?,float?,float?
torch.ops.aten.upsample_trilinear3d.vec(input,output_size,align_corners,scale_factors)|Tensor,SymInt[]?,bool,float[]?
torch.ops.aten.upsample_trilinear3d.out(self,output_size,align_corners,scales_d,scales_h,scales_w,out)|Tensor,SymInt[3],bool,float?,float?,float?,Tensor(a!)
torch.ops.aten.var(self,unbiased)|Tensor,bool
torch.ops.aten.var.dim(self,dim,unbiased,keepdim)|Tensor,int[1]?,bool,bool
torch.ops.aten.var.correction(self,dim,correction,keepdim)|Tensor,int[1]?,Scalar?,bool
torch.ops.aten.var.names_dim(self,dim,unbiased,keepdim)|Tensor,str[1],bool,bool
torch.ops.aten.var.names_out(self,dim,unbiased,keepdim,out)|Tensor,str[1],bool,bool,Tensor(a!)
torch.ops.aten.var.out(self,dim,unbiased,keepdim,out)|Tensor,int[1]?,bool,bool,Tensor(a!)
torch.ops.aten.var.correction_out(self,dim,correction,keepdim,out)|Tensor,int[1]?,Scalar?,bool,Tensor(a!)
torch.ops.aten.var.correction_names(self,dim,correction,keepdim)|Tensor,str[1],Scalar?,bool
torch.ops.aten.var.correction_names_out(self,dim,correction,keepdim,out)|Tensor,str[1],Scalar?,bool,Tensor(a!)
torch.ops.aten.var_mean(self,unbiased)|Tensor,bool
torch.ops.aten.var_mean.dim(self,dim,unbiased,keepdim)|Tensor,int[1]?,bool,bool
torch.ops.aten.var_mean.correction(self,dim,correction,keepdim)|Tensor,int[1]?,Scalar?,bool
torch.ops.aten.var_mean.names_dim(self,dim,unbiased,keepdim)|Tensor,str[1],bool,bool
torch.ops.aten.var_mean.correction_names(self,dim,correction,keepdim)|Tensor,str[1],Scalar?,bool
torch.ops.aten.var_mean.correction_out(self,dim,correction,keepdim,out0,out1)|Tensor,int[1]?,Scalar?,bool,Tensor(a!),Tensor(b!)
torch.ops.aten.vdot(self,other)|Tensor,Tensor
torch.ops.aten.vdot.out(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.view(self,size)|Tensor(a),SymInt[]
torch.ops.aten.view.dtype(self,dtype)|Tensor(a),ScalarType
torch.ops.aten.view_as_complex(self)|Tensor(a)
torch.ops.aten.view_as_real(self)|Tensor(a)
torch.ops.aten.view_copy(self,size)|Tensor,SymInt[]
torch.ops.aten.view_copy.out(self,size,out)|Tensor,SymInt[],Tensor(a!)
torch.ops.aten.view_copy.dtype_out(self,dtype,out)|Tensor,ScalarType,Tensor(a!)
torch.ops.aten.view_copy.dtype(self,dtype)|Tensor,ScalarType
torch.ops.aten.where.self(condition,self,other)|Tensor,Tensor,Tensor
torch.ops.aten.where.ScalarOther(condition,self,other)|Tensor,Tensor,Scalar
torch.ops.aten.where.ScalarSelf(condition,self,other)|Tensor,Scalar,Tensor
torch.ops.aten.where.Scalar(condition,self,other)|Tensor,Scalar,Scalar
torch.ops.aten.where(condition)|Tensor
torch.ops.aten.where.self_out(condition,self,other,out)|Tensor,Tensor,Tensor,Tensor(a!)
torch.ops.aten.xlogy.Tensor(self,other)|Tensor,Tensor
torch.ops.aten.xlogy.Scalar_Other(self,other)|Tensor,Scalar
torch.ops.aten.xlogy.Scalar_Self(self,other)|Scalar,Tensor
torch.ops.aten.xlogy.OutTensor(self,other,out)|Tensor,Tensor,Tensor(a!)
torch.ops.aten.xlogy.OutScalar_Self(self,other,out)|Scalar,Tensor,Tensor(a!)
torch.ops.aten.xlogy.OutScalar_Other(self,other,out)|Tensor,Scalar,Tensor(a!)
torch.ops.aten.xlogy_.Tensor(self,other)|Tensor(a!),Tensor
torch.ops.aten.xlogy_.Scalar_Other(self,other)|Tensor(a!),Scalar
torch.ops.aten.zero(self)|Tensor
torch.ops.aten.zero.out(self,out)|Tensor,Tensor(a!)
torch.ops.aten.zero_(self)|Tensor(a!)
torch.ops.aten.zeros.names(size,names,dtype,layout,device,pin_memory)|int[],str[]?,ScalarType?,Layout?,Device?,bool?
torch.ops.aten.zeros(size,dtype,layout,device,pin_memory)|SymInt[],ScalarType?,Layout?,Device?,bool?
torch.ops.aten.zeros.names_out(size,names,out)|int[],str[]?,Tensor(a!)
torch.ops.aten.zeros.out(size,out)|SymInt[],Tensor(a!)
torch.ops.aten.zeros_like(self,dtype,layout,device,pin_memory,memory_format)|Tensor,ScalarType?,Layout?,Device?,bool?,MemoryFormat?
torch.ops.aten.zeros_like.out(self,memory_format,out)|Tensor,MemoryFormat?,Tensor(a!)
